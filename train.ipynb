{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入(这段读的是aigame作业的下发json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json = []\n",
    "\n",
    "aigame_botid = [\"6048fc6b81fb3b738e911e3b\",\n",
    "               \"6048fcf381fb3b738e912cb8\",\n",
    "               \"6048fd3781fb3b738e9138ac\",\n",
    "               \"6048fd7981fb3b738e9140fc\",\n",
    "               \"6048fda981fb3b738e914488\"]\n",
    "\n",
    "def get_all_json(cwd):\n",
    "    cur_dir = os.listdir(cwd)  \n",
    "    for i in cur_dir:\n",
    "        sub_dir = os.path.join(cwd, i)\n",
    "        if os.path.isdir(sub_dir):\n",
    "            get_all_json(sub_dir)\n",
    "        else:\n",
    "            if i[-5:] == \".json\":\n",
    "                all_json.append(cwd + \"/\" + i)\n",
    "def check_nb(bot_id):\n",
    "    return bot_id == aigame_botid[2]\n",
    "                \n",
    "get_all_json(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入(这段读的是botzone上下载的对局数据，nb_bots是天梯上排名前30的botid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理 Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCardId(card):\n",
    "    # 求一张牌的 id\n",
    "    if card < 52:\n",
    "        return card // 4\n",
    "    else:\n",
    "        return card - 39\n",
    "\n",
    "def getCombo(cards):\n",
    "    # a combo is represented as a tuple(k, l, r, w)\n",
    "    # 表示有 k * [l, r] 即 k 张 [l, r] 中的牌（作为主体）w \\in [0, 1, 2] 表示带的是啥类型\n",
    "    if len(cards) == 0:\n",
    "        return (0, 0, 0, 0)\n",
    "    tmp = np.zeros(15, dtype = int)\n",
    "    for card in cards:\n",
    "        tmp[getCardId(card)] += 1\n",
    "    k = np.max(tmp)\n",
    "    l = np.min(np.where(tmp == k))\n",
    "    r = np.max(np.where(tmp == k))\n",
    "    w = 0\n",
    "    if k == 3:\n",
    "        w = len(cards) // (r - l + 1) - 3\n",
    "    if k == 4:\n",
    "        w = (len(cards) // (r - l + 1) - 4) // 2\n",
    "    return (k, l, r, w)\n",
    "\n",
    "combo_dict = {}\n",
    "combo_list = []\n",
    "combo_cnt = 0\n",
    "\n",
    "def initCombo():\n",
    "    global combo_dict, combo_list, combo_cnt\n",
    "    combo_dict = {}\n",
    "    combo_list = []\n",
    "    combo_cnt = 0\n",
    "    def addCombo(combo):\n",
    "        global combo_dict, combo_list, combo_cnt\n",
    "        combo_list.append(combo)\n",
    "        combo_dict[combo] = combo_cnt\n",
    "        combo_cnt += 1\n",
    "\n",
    "    minLength = [0, 5, 3, 2, 2]\n",
    "    maxWings = [0, 1, 1, 3, 3]\n",
    "    fold = [0, 0, 0, 1, 2]\n",
    "    for k in range(1, 5):\n",
    "        for x in range(13):\n",
    "            for w in range(maxWings[k]):\n",
    "                addCombo((k, x, x, w))\n",
    "        for l in range(12):\n",
    "            for r in range(l + minLength[k] - 1, 12):\n",
    "                for w in range(maxWings[k]):\n",
    "                    if (r - l + 1) * (k + w * fold[k]) <= 20:\n",
    "                        addCombo((k, l, r, w))\n",
    "    addCombo((1, 13, 13, 0))\n",
    "    addCombo((1, 14, 14, 0))\n",
    "    addCombo((1, 13, 14, 0))\n",
    "    addCombo((0, 0, 0, 0))\n",
    "    \n",
    "initCombo()\n",
    "\n",
    "def getPartition(cards):\n",
    "    # 把一次出牌的编号集合划分成 mainbody 和 bywings\n",
    "    # 其中 mainbody 是一个 list ，bywings 中每个 wing 是一个 list ，也就是一个 list 的 list\n",
    "    combo = getCombo(cards)\n",
    "    tmp = [[] for i in range(15)]\n",
    "    for card in cards:\n",
    "        tmp[getCardId(card)].append(card)\n",
    "    mainbody, bywings = [], []\n",
    "    for i in range(15):\n",
    "        if len(tmp[i]) > 0:\n",
    "            if combo[1] <= i and i <= combo[2]:\n",
    "                mainbody.extend(tmp[i])\n",
    "            else:\n",
    "                bywings.append(tmp[i])\n",
    "    return mainbody, bywings\n",
    "\n",
    "def getComboMask(combo):\n",
    "    # 给出一个 combo ，返回可以接在其后面牌型 mask \n",
    "    mask = np.zeros(combo_cnt)\n",
    "    if combo == (0, 0, 0, 0):\n",
    "        mask = np.ones(combo_cnt)\n",
    "        mask[combo_dict[(0, 0, 0, 0)]] = 0\n",
    "        return mask\n",
    "    mask[combo_dict[(0, 0, 0, 0)]] = 1\n",
    "\n",
    "    if combo == (1, 13, 14, 0):\n",
    "        return mask\n",
    "    mask[combo_dict[(1, 13, 14, 0)]] = 1\n",
    "\n",
    "    if combo[0] == 4 and combo[1] == combo[2] and combo[3] == 0:\n",
    "        for i in range(combo[1] + 1, 13):\n",
    "            mask[combo_dict[(4, i, i, 0)]] = 1\n",
    "        return mask\n",
    "    for i in range(13):\n",
    "        mask[combo_dict[(4, i, i, 0)]] = 1\n",
    "\n",
    "    for cb in combo_list:\n",
    "        if cb[0] == combo[0] and cb[2] - cb[1] == combo[2] - combo[1] and cb[3] == combo[3] and cb[1] > combo[1]:\n",
    "            mask[combo_dict[cb]] = 1\n",
    "            \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_size = 0\n",
    "\n",
    "class Game(object):\n",
    "    # 这里 0 始终是地主，1 始终是地主下家，2 始终是地主上家\n",
    "\n",
    "    def __init__(self, init_data):\n",
    "        self.hand = np.zeros((3, 15), dtype = int)\n",
    "        for player in range(3):\n",
    "            for card in init_data[player]:\n",
    "                self.hand[player, getCardId(card)] += 1\n",
    "        self.initial_hand = self.hand.copy()\n",
    "    \n",
    "    def play(self, player, cards):\n",
    "        # 模拟打牌 打出 cards 这个 list 中的所有牌\n",
    "        for card in cards:\n",
    "            self.hand[player, getCardId(card)] -= 1\n",
    "            \n",
    "    def possess(self, player, combo):\n",
    "        # 判断 player 这个玩家是否拥有 combo 这个牌型的牌\n",
    "        if combo == (0, 0, 0, 0):\n",
    "            return True\n",
    "        for i in range(combo[1], combo[2] + 1):\n",
    "            if self.hand[player, i] < combo[0]:\n",
    "                return False\n",
    "            \n",
    "        fold = [0, 0, 0, 1, 2]\n",
    "        need_wings = (combo[2] - combo[1] + 1) * fold[combo[0]] if combo[3] > 0 else 0\n",
    "        for i in range(15):\n",
    "            if i < combo[1] or i > combo[2]:\n",
    "                if self.hand[player, i] >= combo[3]:\n",
    "                    need_wings -= 1\n",
    "        if need_wings > 0:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def getPossessMask(self, player):\n",
    "        # 返回 player 拥有的牌型 mask\n",
    "        mask = np.zeros(combo_cnt)\n",
    "        for i in range(combo_cnt):\n",
    "            if self.possess(player, combo_list[i]) == True:\n",
    "                mask[i] = 1\n",
    "        return mask\n",
    "    \n",
    "    def getMask1(self, player, combo):\n",
    "        # getPossessMask 和 getComboMask 取交集\n",
    "        return self.getPossessMask(player) * getComboMask(combo)\n",
    "    \n",
    "    def getMask2(self, player, combo, already_played):\n",
    "        # 带翼的 mask，哪些翼是可以打的？\n",
    "        # mask 的大小是 15 或者 13, 表示 15 种单牌和 13 种对子\n",
    "        # 指明 combo 后：(1)少于1/2张的不能打 (2)和主体部分重复的不能打 (3)打过的不能打\n",
    "        mask = np.ones(15 if combo[3] == 1 else 13)\n",
    "        for i in range(mask.shape[0]):\n",
    "                if self.hand[player, i] < combo[3]:\n",
    "                    mask[i] = 0\n",
    "        mask[range(combo[1], combo[2] + 1)] = 0\n",
    "        mask[already_played] = 0\n",
    "        return mask\n",
    "        \n",
    "    def getInput(self, player, combos):\n",
    "        global _input_size\n",
    "        \n",
    "        p1 = (player + 1) % 3\n",
    "        p2 = (player + 2) % 3\n",
    "        '''\n",
    "        myhand = np.zeros((4, 15))\n",
    "        othershand = np.zeros((4, 15))\n",
    "        for i in range(4):\n",
    "            myhand[i, np.where(self.hand[player] == i + 1)] = 1\n",
    "            othershand[i, np.where(self.hand[p1] + self.hand[p2] == i + 1)] = 1\n",
    "        \n",
    "        played_cards = np.zeros((3, 4, 15))\n",
    "        p_list = [player, p1, p2]\n",
    "        for i in range(3):\n",
    "            p = p_list[i]\n",
    "            for j in range(4):\n",
    "                played_cards[i, j, np.where(self.initial_hand[p] - self.hand[p] == j + 1)] = 1\n",
    "                \n",
    "        handcnt = np.zeros((3, 20))\n",
    "        for player in range(3):\n",
    "            handcnt[player, range(np.sum(self.hand[player]))] = 1\n",
    "        \n",
    "        Input = np.concatenate([myhand.flatten(),\n",
    "                               othershand.flatten(),\n",
    "                               played_cards.flatten(),\n",
    "                               handcnt.flatten()\n",
    "#                               self.getPossessMask(player)\n",
    "                              ])\n",
    "        '''\n",
    "        # 我手里有每种数值的牌多少张，对手还有每种数值的牌多少张没有出过\n",
    "        Input = np.concatenate([np.array(self.hand[player]),\n",
    "                                np.array(self.hand[p1]) + np.array(self.hand[p2])])\n",
    "        # 我们三个人各打过每个数值多少张牌，各还有多少张牌\n",
    "        for p in range(3):\n",
    "            Input = np.concatenate([Input,\n",
    "                                    np.array(self.initial_hand[p]) - np.array(self.hand[p]),\n",
    "                                    np.array([np.sum(self.hand[p])])\n",
    "                                   ])\n",
    "        def getComboArray(combo):\n",
    "            tmp = np.zeros(15)\n",
    "            for i in range(combo[1], combo[2] + 1):\n",
    "                tmp[i] += combo[0]\n",
    "            return tmp\n",
    "        # 前两回合那两个人各出了什么牌型的牌（只记录主体）\n",
    "        for k in range(1, 2):\n",
    "            for i in range(1, 3):\n",
    "                Input = np.concatenate([Input,\n",
    "                                        getComboArray(combos[(player + i) % 3][-k] if len(combos[(player + i) % 3]) >= k else (0, 0, 0, 0))\n",
    "                                    ])\n",
    "        # 我还有的牌型\n",
    "        Input = np.concatenate([Input, self.getPossessMask(player)])\n",
    "        # 我的手牌的差分(12张可连顺的部分)\n",
    "        tmp = np.zeros(11)\n",
    "        for i in range(11):\n",
    "            tmp[i] = self.hand[player, i + 1] - self.hand[player, i]\n",
    "        Input = np.concatenate([Input, tmp])\n",
    "        _input_size = Input.shape[0]\n",
    "        return Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = []\n",
    "        self.M = []\n",
    "        self.Y = []\n",
    "    def append(self, x, m, y):\n",
    "        self.X.append(x)\n",
    "        self.M.append(m)\n",
    "        self.Y.append(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.M[idx], self.Y[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cdb572bdfadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDS1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDS2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDS1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    254\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# Friendlier error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36mpeek\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DS1, DS2 = np.load('data.npz', allow_pickle=True)['DATA']\n",
    "_input_size = DS1[0][0][0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1 = [MyDataset(), MyDataset(), MyDataset()]\n",
    "DS2 = [MyDataset(), MyDataset()]\n",
    "# DS1 是三个玩家分别的出牌数据集，可能处于不同位置会有不同的出牌策略所以分别训练了网络\n",
    "# DS2 是带牌数据集，分别是单排和顺子，因为数据量比较少而且感觉三个人没什么太大区别就合并到一起了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "files = 1, lengths = (0, 0, 0, 0, 0)\n",
      "files = 2, lengths = (0, 0, 0, 0, 0)\n",
      "files = 3, lengths = (0, 0, 0, 0, 0)\n",
      "files = 4, lengths = (0, 0, 0, 0, 0)\n",
      "files = 5, lengths = (0, 0, 0, 0, 0)\n",
      "files = 6, lengths = (0, 0, 0, 0, 0)\n",
      "files = 7, lengths = (0, 0, 0, 0, 0)\n",
      "files = 8, lengths = (0, 0, 0, 0, 0)\n",
      "files = 9, lengths = (0, 0, 0, 0, 0)\n",
      "files = 10, lengths = (0, 0, 0, 0, 0)\n",
      "files = 11, lengths = (0, 0, 0, 0, 0)\n",
      "files = 12, lengths = (0, 0, 0, 0, 0)\n",
      "files = 13, lengths = (0, 0, 0, 0, 0)\n",
      "files = 14, lengths = (0, 0, 0, 0, 0)\n",
      "files = 15, lengths = (0, 0, 0, 0, 0)\n",
      "files = 16, lengths = (0, 0, 0, 0, 0)\n",
      "files = 17, lengths = (0, 0, 0, 0, 0)\n",
      "files = 18, lengths = (0, 0, 0, 0, 0)\n",
      "files = 19, lengths = (0, 0, 0, 0, 0)\n",
      "files = 20, lengths = (0, 0, 0, 0, 0)\n",
      "files = 21, lengths = (0, 0, 0, 0, 0)\n",
      "files = 22, lengths = (0, 0, 0, 0, 0)\n",
      "files = 23, lengths = (0, 0, 0, 0, 0)\n",
      "files = 24, lengths = (0, 0, 0, 0, 0)\n",
      "files = 25, lengths = (0, 0, 0, 0, 0)\n",
      "files = 26, lengths = (0, 0, 0, 0, 0)\n",
      "files = 27, lengths = (0, 0, 0, 0, 0)\n",
      "files = 28, lengths = (0, 0, 0, 0, 0)\n",
      "files = 29, lengths = (0, 0, 0, 0, 0)\n",
      "files = 30, lengths = (0, 0, 0, 0, 0)\n",
      "files = 31, lengths = (0, 0, 0, 0, 0)\n",
      "files = 32, lengths = (0, 0, 0, 0, 0)\n",
      "files = 33, lengths = (0, 0, 0, 0, 0)\n",
      "files = 34, lengths = (0, 0, 0, 0, 0)\n",
      "files = 35, lengths = (0, 0, 0, 0, 0)\n",
      "files = 36, lengths = (0, 0, 0, 0, 0)\n",
      "files = 37, lengths = (0, 0, 0, 0, 0)\n",
      "files = 38, lengths = (0, 0, 0, 0, 0)\n",
      "files = 39, lengths = (0, 0, 0, 0, 0)\n",
      "files = 40, lengths = (0, 0, 0, 0, 0)\n",
      "files = 41, lengths = (0, 0, 0, 0, 0)\n",
      "files = 42, lengths = (0, 0, 0, 0, 0)\n",
      "files = 43, lengths = (0, 0, 0, 0, 0)\n",
      "files = 44, lengths = (0, 0, 0, 0, 0)\n",
      "files = 45, lengths = (0, 0, 0, 0, 0)\n",
      "files = 46, lengths = (0, 0, 0, 0, 0)\n",
      "files = 47, lengths = (0, 0, 0, 0, 0)\n",
      "files = 48, lengths = (0, 0, 0, 0, 0)\n",
      "files = 49, lengths = (0, 0, 0, 0, 0)\n",
      "files = 50, lengths = (0, 0, 0, 0, 0)\n",
      "files = 51, lengths = (0, 0, 0, 0, 0)\n",
      "files = 52, lengths = (0, 0, 0, 0, 0)\n",
      "files = 53, lengths = (0, 0, 0, 0, 0)\n",
      "files = 54, lengths = (0, 0, 0, 0, 0)\n",
      "files = 55, lengths = (0, 0, 0, 0, 0)\n",
      "files = 56, lengths = (0, 0, 0, 0, 0)\n",
      "files = 57, lengths = (0, 0, 0, 0, 0)\n",
      "files = 58, lengths = (0, 0, 0, 0, 0)\n",
      "files = 59, lengths = (0, 0, 0, 0, 0)\n",
      "files = 60, lengths = (0, 0, 0, 0, 0)\n",
      "files = 61, lengths = (0, 0, 0, 0, 0)\n",
      "files = 62, lengths = (0, 0, 0, 0, 0)\n",
      "files = 63, lengths = (0, 0, 0, 0, 0)\n",
      "files = 64, lengths = (0, 0, 0, 0, 0)\n",
      "files = 65, lengths = (0, 0, 0, 0, 0)\n",
      "files = 66, lengths = (0, 0, 0, 0, 0)\n",
      "files = 67, lengths = (679, 659, 676, 132, 61)\n",
      "files = 68, lengths = (1491, 1361, 1422, 263, 113)\n",
      "files = 69, lengths = (3619, 3385, 3459, 639, 272)\n",
      "files = 70, lengths = (4173, 3900, 3999, 724, 325)\n",
      "files = 71, lengths = (5314, 4877, 5034, 932, 428)\n",
      "files = 72, lengths = (6570, 6012, 6174, 1129, 531)\n",
      "files = 73, lengths = (7050, 6488, 6644, 1234, 565)\n",
      "files = 74, lengths = (13427, 12181, 12463, 2198, 910)\n",
      "files = 75, lengths = (14194, 12931, 13232, 2346, 983)\n",
      "files = 76, lengths = (15014, 13669, 13986, 2469, 1042)\n",
      "files = 77, lengths = (15471, 14044, 14389, 2550, 1074)\n",
      "files = 78, lengths = (16429, 14822, 15174, 2700, 1141)\n",
      "files = 79, lengths = (17007, 15287, 15619, 2794, 1196)\n",
      "files = 80, lengths = (17279, 15510, 15857, 2844, 1222)\n",
      "files = 81, lengths = (17400, 15607, 15960, 2868, 1227)\n",
      "files = 82, lengths = (17530, 15720, 16067, 2882, 1241)\n",
      "files = 83, lengths = (17979, 16067, 16450, 2962, 1263)\n",
      "files = 84, lengths = (18236, 16273, 16671, 3011, 1281)\n",
      "files = 85, lengths = (18628, 16607, 16992, 3080, 1309)\n",
      "files = 86, lengths = (19594, 17445, 17890, 3272, 1367)\n",
      "files = 87, lengths = (19634, 17486, 17931, 3281, 1370)\n",
      "files = 88, lengths = (20273, 18003, 18497, 3406, 1421)\n",
      "files = 89, lengths = (21066, 18742, 19257, 3540, 1481)\n",
      "files = 90, lengths = (22135, 19720, 20254, 3727, 1572)\n",
      "files = 91, lengths = (22145, 19727, 20258, 3732, 1572)\n",
      "files = 92, lengths = (22384, 19944, 20503, 3766, 1597)\n",
      "files = 93, lengths = (22937, 20365, 20928, 3890, 1620)\n",
      "files = 94, lengths = (23735, 21118, 21756, 4018, 1684)\n",
      "files = 95, lengths = (25103, 22398, 23157, 4252, 1781)\n",
      "files = 96, lengths = (25783, 23021, 23830, 4393, 1846)\n",
      "files = 97, lengths = (26412, 23567, 24396, 4528, 1909)\n",
      "files = 98, lengths = (26914, 24063, 24925, 4639, 1956)\n",
      "files = 99, lengths = (27354, 24451, 25366, 4727, 1988)\n",
      "files = 100, lengths = (28373, 25308, 26217, 4908, 2064)\n",
      "files = 101, lengths = (29042, 25849, 26835, 5047, 2128)\n",
      "files = 102, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 103, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 104, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 105, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 106, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 107, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 108, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 109, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 110, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 111, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 112, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 113, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 114, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 115, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 116, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 117, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 118, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 119, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 120, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 121, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 122, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 123, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 124, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 125, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 126, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 127, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 128, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 129, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 130, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 131, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 132, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 133, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 134, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 135, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 136, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 137, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 138, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 139, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 140, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 141, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 142, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 143, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 144, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 145, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 146, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 147, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 148, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 149, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 150, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 151, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 152, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 153, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 154, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 155, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 156, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 157, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 158, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 159, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 160, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 161, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 162, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 163, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 164, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 165, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 166, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 167, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 168, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 169, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 170, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 171, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 172, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 173, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 174, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 175, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 176, lengths = (29680, 26425, 27414, 5166, 2189)\n",
      "files = 177, lengths = (29680, 26425, 27414, 5166, 2189)\n"
     ]
    }
   ],
   "source": [
    "file_cnt = 0\n",
    "\n",
    "for file in all_json:\n",
    "#    print(file)\n",
    "    with open(file, 'r+') as f:\n",
    "        while True:\n",
    "            data = f.readline()\n",
    "            if(len(data) == 0):\n",
    "                break\n",
    "            try:\n",
    "                data = json.loads(data)\n",
    "                initdata = json.loads(data['initdata'])\n",
    "\n",
    "                nb_bot = [0, 0, 0]\n",
    "                exists_nb = 0\n",
    "                for i in range(3):\n",
    "                    if \"bot\" in data['players'][i].keys() and check_nb(data['players'][i]['bot']):\n",
    "                        nb_bot[i] = 1\n",
    "                        exists_nb = 1\n",
    "                if exists_nb == 0:\n",
    "                    break\n",
    "\n",
    "                g = Game(initdata['allocation'])\n",
    "                log = data['log']\n",
    "\n",
    "                combos = [[(0, 0, 0, 0)], [(0, 0, 0, 0)], [(0, 0, 0, 0)]]\n",
    "                las_play = -1\n",
    "\n",
    "                for i in range(1, len(log), 2):\n",
    "                    player = -1\n",
    "                    for p in range(3):\n",
    "                        if str(p) in log[i]:\n",
    "                            player = p\n",
    "                            break\n",
    "\n",
    "                    if log[i][str(p)]['verdict'] != 'OK':\n",
    "                        print(log[i][str(p)]['verdict'])\n",
    "                        break\n",
    "\n",
    "                    cards = log[i][str(player)]['response']\n",
    "                    combos[player].append(getCombo(cards))\n",
    "                    mainbody, bywings = getPartition(cards)\n",
    "                    las_combo = (0, 0, 0, 0)\n",
    "                    for i in range(1, 3):\n",
    "                        if combos[(player + i) % 3][-1] != (0, 0, 0, 0):\n",
    "                            las_combo = combos[(player + i) % 3][-1]\n",
    "\n",
    "                    if nb_bot[player]:\n",
    "                        input_x = g.getInput(player, combos)\n",
    "                        input_m = g.getMask1(player, las_combo)\n",
    "                        output_y = combo_dict[combos[player][-1]]\n",
    "                        assert input_m[output_y] == 1\n",
    "                        if np.sum(input_m) > 1:\n",
    "                            DS1[player].append(input_x, input_m, output_y)\n",
    "\n",
    "                    g.play(player, mainbody)\n",
    "\n",
    "                    if len(bywings) != 0:\n",
    "                        already_played = []\n",
    "                        for w in bywings:\n",
    "                            assert len(w) == 1 or len(w) == 2\n",
    "                            if nb_bot[player]:\n",
    "                                input_x = g.getInput(player, combos)\n",
    "                                input_m = g.getMask2(player, combos[player][-1], already_played)\n",
    "                                output_y = getCardId(w[0])\n",
    "                                assert input_m[output_y] == 1\n",
    "                                DS2[0 if len(w) == 1 else 1].append(input_x, input_m, output_y)\n",
    "\n",
    "                            g.play(player, w)\n",
    "                            already_played.append(getCardId(w[0]))                    \n",
    "                            \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    file_cnt += 1\n",
    "    if file_cnt % 1 == 0:\n",
    "        print(\"files = %d, lengths = (%d, %d, %d, %d, %d)\"\n",
    "              % (file_cnt, len(DS1[0]), len(DS1[1]), len(DS1[2]), len(DS2[0]), len(DS2[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_input_size =  498\n29680 26425 27414 5166 2189\n"
     ]
    }
   ],
   "source": [
    "print(\"_input_size = \", _input_size)\n",
    "print(len(DS1[0]), len(DS1[1]), len(DS1[2]), len(DS2[0]), len(DS2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/lijiaheng/opt/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.savez('data', DATA=(DS1, DS2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS10, DS20 = np.load('data.npz', allow_pickle=True)['DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29680 26425 27414 5166 2189\n"
     ]
    }
   ],
   "source": [
    "print(len(DS10[0]), len(DS10[1]), len(DS10[2]), len(DS20[0]), len(DS20[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果读的是aigame的第一个bot，那么五个数据集的大小应该分别是 23785 20027 21129 6697 957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 1024\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, INPUT_SIZE, OUTPUT_SIZE):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "                ('fc1', nn.Linear(INPUT_SIZE, HIDDEN_SIZE)),\n",
    "                ('dropout', nn.Dropout(p = 0.5)),\n",
    "                ('bn', nn.BatchNorm1d(HIDDEN_SIZE)),\n",
    "                ('relu', nn.ReLU()),\n",
    "                ('fc2', nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)),\n",
    "                # ('dropout2', nn.Dropout(p = 0.5)),\n",
    "                # ('bn2', nn.BatchNorm1d(OUTPUT_SIZE)),\n",
    "            ]))\n",
    "        \n",
    "    def forward(self, x, m):\n",
    "        return self.fc(x) * m\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练（主体）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "def getPred(output):\n",
    "    return output.detach().numpy().argmax(axis = 1)\n",
    "\n",
    "def train(net, data_loader, data_size, criterion, optimizer):\n",
    "    net.train()\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(x, m)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        output = net(x, m)\n",
    "        avg_loss += criterion(output, y).sum()\n",
    "        pred = getPred(output)\n",
    "        total_correct += (pred == y.detach().numpy()).sum()\n",
    "    avg_loss /= data_size\n",
    "    cur_acc = float(total_correct) / data_size\n",
    "    print('Training Avg. Loss: %f, Accuracy: %f' % (avg_loss, cur_acc))\n",
    "\n",
    "def validate(net, data_loader, data_size, criterion, model_name):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        output = net(x, m)\n",
    "        avg_loss += criterion(output, y).sum()\n",
    "        pred = getPred(output)\n",
    "        total_correct += (pred == y.detach().numpy()).sum()\n",
    "    \n",
    "    avg_loss /= data_size\n",
    "    cur_acc = float(total_correct) / data_size\n",
    "    print('Validation Avg. Loss: %f, Accuracy: %f' % (avg_loss, cur_acc))\n",
    "    \n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        torch.save(net, './model/best_model_for_' + model_name + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------------------------\n",
      "Training model 0\n",
      "-----------------------------------------\n",
      "MyModule(\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=498, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=1024, out_features=379, bias=True)\n",
      "  )\n",
      ")\n",
      "train_size =  28196 valid_size =  1484\n",
      "epoch =  0\n",
      "Training Avg. Loss: 0.003739, Accuracy: 0.469889\n",
      "Validation Avg. Loss: 0.007201, Accuracy: 0.469677\n",
      "epoch =  1\n",
      "Training Avg. Loss: 0.002518, Accuracy: 0.635019\n",
      "Validation Avg. Loss: 0.006083, Accuracy: 0.633423\n",
      "epoch =  2\n",
      "Training Avg. Loss: 0.002092, Accuracy: 0.702795\n",
      "Validation Avg. Loss: 0.005099, Accuracy: 0.681941\n",
      "epoch =  3\n",
      "Training Avg. Loss: 0.001834, Accuracy: 0.741559\n",
      "Validation Avg. Loss: 0.004286, Accuracy: 0.727089\n",
      "epoch =  4\n",
      "Training Avg. Loss: 0.001636, Accuracy: 0.770003\n",
      "Validation Avg. Loss: 0.003686, Accuracy: 0.743935\n",
      "epoch =  5\n",
      "Training Avg. Loss: 0.001495, Accuracy: 0.790999\n",
      "Validation Avg. Loss: 0.003137, Accuracy: 0.764825\n",
      "epoch =  6\n",
      "Training Avg. Loss: 0.001375, Accuracy: 0.809618\n",
      "Validation Avg. Loss: 0.002757, Accuracy: 0.784367\n",
      "epoch =  7\n",
      "Training Avg. Loss: 0.001273, Accuracy: 0.824621\n",
      "Validation Avg. Loss: 0.002487, Accuracy: 0.789084\n",
      "epoch =  8\n",
      "Training Avg. Loss: 0.001184, Accuracy: 0.835012\n",
      "Validation Avg. Loss: 0.002229, Accuracy: 0.803908\n",
      "epoch =  9\n",
      "Training Avg. Loss: 0.001112, Accuracy: 0.845510\n",
      "Validation Avg. Loss: 0.002030, Accuracy: 0.814016\n",
      "epoch =  10\n",
      "Training Avg. Loss: 0.001040, Accuracy: 0.857604\n",
      "Validation Avg. Loss: 0.001900, Accuracy: 0.826146\n",
      "epoch =  11\n",
      "Training Avg. Loss: 0.000978, Accuracy: 0.866009\n",
      "Validation Avg. Loss: 0.001776, Accuracy: 0.828841\n",
      "epoch =  12\n",
      "Training Avg. Loss: 0.000930, Accuracy: 0.871790\n",
      "Validation Avg. Loss: 0.001671, Accuracy: 0.833558\n",
      "epoch =  13\n",
      "Training Avg. Loss: 0.000887, Accuracy: 0.879948\n",
      "Validation Avg. Loss: 0.001598, Accuracy: 0.840296\n",
      "epoch =  14\n",
      "Training Avg. Loss: 0.000851, Accuracy: 0.882643\n",
      "Validation Avg. Loss: 0.001489, Accuracy: 0.847709\n",
      "epoch =  15\n",
      "Training Avg. Loss: 0.000812, Accuracy: 0.891048\n",
      "Validation Avg. Loss: 0.001454, Accuracy: 0.844340\n",
      "epoch =  16\n",
      "Training Avg. Loss: 0.000770, Accuracy: 0.894382\n",
      "Validation Avg. Loss: 0.001411, Accuracy: 0.841644\n",
      "epoch =  17\n",
      "Training Avg. Loss: 0.000744, Accuracy: 0.898851\n",
      "Validation Avg. Loss: 0.001356, Accuracy: 0.843666\n",
      "epoch =  18\n",
      "Training Avg. Loss: 0.000715, Accuracy: 0.902043\n",
      "Validation Avg. Loss: 0.001307, Accuracy: 0.846361\n",
      "epoch =  19\n",
      "Training Avg. Loss: 0.000693, Accuracy: 0.906724\n",
      "Validation Avg. Loss: 0.001285, Accuracy: 0.858491\n",
      "epoch =  20\n",
      "Training Avg. Loss: 0.000666, Accuracy: 0.909668\n",
      "Validation Avg. Loss: 0.001259, Accuracy: 0.849057\n",
      "epoch =  21\n",
      "Training Avg. Loss: 0.000641, Accuracy: 0.911548\n",
      "Validation Avg. Loss: 0.001247, Accuracy: 0.849730\n",
      "epoch =  22\n",
      "Training Avg. Loss: 0.000609, Accuracy: 0.917612\n",
      "Validation Avg. Loss: 0.001216, Accuracy: 0.854447\n",
      "epoch =  23\n",
      "Training Avg. Loss: 0.000593, Accuracy: 0.922436\n",
      "Validation Avg. Loss: 0.001186, Accuracy: 0.852426\n",
      "epoch =  24\n",
      "Training Avg. Loss: 0.000574, Accuracy: 0.921159\n",
      "Validation Avg. Loss: 0.001169, Accuracy: 0.857143\n",
      "epoch =  25\n",
      "Training Avg. Loss: 0.000560, Accuracy: 0.923571\n",
      "Validation Avg. Loss: 0.001163, Accuracy: 0.856469\n",
      "epoch =  26\n",
      "Training Avg. Loss: 0.000536, Accuracy: 0.928962\n",
      "Validation Avg. Loss: 0.001133, Accuracy: 0.855121\n",
      "epoch =  27\n",
      "Training Avg. Loss: 0.000519, Accuracy: 0.930274\n",
      "Validation Avg. Loss: 0.001124, Accuracy: 0.855121\n",
      "epoch =  28\n",
      "Training Avg. Loss: 0.000515, Accuracy: 0.929635\n",
      "Validation Avg. Loss: 0.001125, Accuracy: 0.860512\n",
      "epoch =  29\n",
      "Training Avg. Loss: 0.000490, Accuracy: 0.934778\n",
      "Validation Avg. Loss: 0.001125, Accuracy: 0.854447\n",
      "epoch =  30\n",
      "Training Avg. Loss: 0.000480, Accuracy: 0.935487\n",
      "Validation Avg. Loss: 0.001106, Accuracy: 0.853774\n",
      "epoch =  31\n",
      "Training Avg. Loss: 0.000466, Accuracy: 0.936516\n",
      "Validation Avg. Loss: 0.001098, Accuracy: 0.855121\n",
      "epoch =  32\n",
      "Training Avg. Loss: 0.000458, Accuracy: 0.938786\n",
      "Validation Avg. Loss: 0.001113, Accuracy: 0.856469\n",
      "epoch =  33\n",
      "Training Avg. Loss: 0.000449, Accuracy: 0.938254\n",
      "Validation Avg. Loss: 0.001093, Accuracy: 0.856469\n",
      "epoch =  34\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0eb3c541cdbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               optimizer = optim.Adam(net.parameters(), lr = 3e-4))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#              optimizer = optim.SGD(net.parameters(), lr = 2e-3, momentum=0.9))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         validate(net, data_loader = valid_loader,\n",
      "\u001b[0;32m<ipython-input-36-7ff972a57de1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, data_size, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "        \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Training model %d\" % i)\n",
    "    print(\"-----------------------------------------\")\n",
    "\n",
    "    net = MyModule(_input_size, combo_cnt)\n",
    "    print(net)\n",
    "    best_acc = 0\n",
    "    \n",
    "    train_size = int(0.95 * len(DS1[i]))\n",
    "    valid_size = len(DS1[i]) - train_size\n",
    "    print(\"train_size = \", train_size, \"valid_size = \", valid_size)\n",
    "\n",
    "\n",
    "    train_data, valid_data = torch.utils.data.random_split(DS1[i], [train_size, valid_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 512)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = 512)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        print(\"epoch = \", epoch)\n",
    "        train(net, data_loader = train_loader,\n",
    "              data_size = train_size,\n",
    "              criterion = nn.CrossEntropyLoss(),\n",
    "              optimizer = optim.Adam(net.parameters(), lr = 3e-4))\n",
    "#              optimizer = optim.SGD(net.parameters(), lr = 2e-3, momentum=0.9))\n",
    "        validate(net, data_loader = valid_loader,\n",
    "                 data_size = valid_size,\n",
    "                 criterion = nn.CrossEntropyLoss(),\n",
    "                 model_name = str(i) + \"mainbody\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练（带翼）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Training model 0\n",
      "-----------------------------------------\n",
      "train_size =  4907 valid_size =  259\n",
      "epoch =  0\n",
      "Training Avg. Loss: 0.008086, Accuracy: 0.826370\n",
      "Validation Avg. Loss: 0.013120, Accuracy: 0.810811\n",
      "epoch =  1\n",
      "Training Avg. Loss: 0.005591, Accuracy: 0.878133\n",
      "Validation Avg. Loss: 0.007780, Accuracy: 0.880309\n",
      "epoch =  2\n",
      "Training Avg. Loss: 0.004262, Accuracy: 0.913593\n",
      "Validation Avg. Loss: 0.008677, Accuracy: 0.884170\n",
      "epoch =  3\n",
      "Training Avg. Loss: 0.004810, Accuracy: 0.900754\n",
      "Validation Avg. Loss: 0.009119, Accuracy: 0.864865\n",
      "epoch =  4\n",
      "Training Avg. Loss: 0.003322, Accuracy: 0.927858\n",
      "Validation Avg. Loss: 0.009354, Accuracy: 0.864865\n",
      "epoch =  5\n",
      "Training Avg. Loss: 0.002821, Accuracy: 0.939067\n",
      "Validation Avg. Loss: 0.007050, Accuracy: 0.907336\n",
      "epoch =  6\n",
      "Training Avg. Loss: 0.002482, Accuracy: 0.949256\n",
      "Validation Avg. Loss: 0.007523, Accuracy: 0.891892\n",
      "epoch =  7\n",
      "Training Avg. Loss: 0.002991, Accuracy: 0.937029\n",
      "Validation Avg. Loss: 0.011163, Accuracy: 0.857143\n",
      "epoch =  8\n",
      "Training Avg. Loss: 0.002290, Accuracy: 0.954147\n",
      "Validation Avg. Loss: 0.010283, Accuracy: 0.868726\n",
      "epoch =  9\n",
      "Training Avg. Loss: 0.002350, Accuracy: 0.953128\n",
      "Validation Avg. Loss: 0.011115, Accuracy: 0.884170\n",
      "epoch =  10\n",
      "Training Avg. Loss: 0.002662, Accuracy: 0.944977\n",
      "Validation Avg. Loss: 0.011470, Accuracy: 0.888031\n",
      "epoch =  11\n",
      "Training Avg. Loss: 0.001751, Accuracy: 0.960261\n",
      "Validation Avg. Loss: 0.012812, Accuracy: 0.868726\n",
      "epoch =  12\n",
      "Training Avg. Loss: 0.002039, Accuracy: 0.956593\n",
      "Validation Avg. Loss: 0.013606, Accuracy: 0.880309\n",
      "epoch =  13\n",
      "Training Avg. Loss: 0.002900, Accuracy: 0.944977\n",
      "Validation Avg. Loss: 0.013218, Accuracy: 0.880309\n",
      "epoch =  14\n",
      "Training Avg. Loss: 0.001809, Accuracy: 0.965356\n",
      "Validation Avg. Loss: 0.012233, Accuracy: 0.903475\n",
      "epoch =  15\n",
      "Training Avg. Loss: 0.002109, Accuracy: 0.960668\n",
      "Validation Avg. Loss: 0.012446, Accuracy: 0.872587\n",
      "epoch =  16\n",
      "Training Avg. Loss: 0.001981, Accuracy: 0.962706\n",
      "Validation Avg. Loss: 0.013091, Accuracy: 0.911197\n",
      "epoch =  17\n",
      "Training Avg. Loss: 0.003051, Accuracy: 0.950683\n",
      "Validation Avg. Loss: 0.020462, Accuracy: 0.891892\n",
      "epoch =  18\n",
      "Training Avg. Loss: 0.002080, Accuracy: 0.963318\n",
      "Validation Avg. Loss: 0.014012, Accuracy: 0.903475\n",
      "epoch =  19\n",
      "Training Avg. Loss: 0.002133, Accuracy: 0.960057\n",
      "Validation Avg. Loss: 0.025989, Accuracy: 0.891892\n",
      "epoch =  20\n",
      "Training Avg. Loss: 0.002241, Accuracy: 0.961280\n",
      "Validation Avg. Loss: 0.018538, Accuracy: 0.899614\n",
      "epoch =  21\n",
      "Training Avg. Loss: 0.003263, Accuracy: 0.953740\n",
      "Validation Avg. Loss: 0.020741, Accuracy: 0.880309\n",
      "epoch =  22\n",
      "Training Avg. Loss: 0.002229, Accuracy: 0.964337\n",
      "Validation Avg. Loss: 0.020604, Accuracy: 0.899614\n",
      "epoch =  23\n",
      "Training Avg. Loss: 0.002726, Accuracy: 0.961076\n",
      "Validation Avg. Loss: 0.018283, Accuracy: 0.888031\n",
      "epoch =  24\n",
      "Training Avg. Loss: 0.002088, Accuracy: 0.969024\n",
      "Validation Avg. Loss: 0.027540, Accuracy: 0.880309\n",
      "epoch =  25\n",
      "Training Avg. Loss: 0.001933, Accuracy: 0.970043\n",
      "Validation Avg. Loss: 0.022812, Accuracy: 0.888031\n",
      "epoch =  26\n",
      "Training Avg. Loss: 0.002104, Accuracy: 0.968616\n",
      "Validation Avg. Loss: 0.022253, Accuracy: 0.891892\n",
      "epoch =  27\n",
      "Training Avg. Loss: 0.002259, Accuracy: 0.965356\n",
      "Validation Avg. Loss: 0.027005, Accuracy: 0.872587\n",
      "epoch =  28\n",
      "Training Avg. Loss: 0.002542, Accuracy: 0.966782\n",
      "Validation Avg. Loss: 0.027588, Accuracy: 0.884170\n",
      "epoch =  29\n",
      "Training Avg. Loss: 0.002097, Accuracy: 0.970858\n",
      "Validation Avg. Loss: 0.026805, Accuracy: 0.911197\n",
      "epoch =  30\n",
      "Training Avg. Loss: 0.002096, Accuracy: 0.968209\n",
      "Validation Avg. Loss: 0.027629, Accuracy: 0.884170\n",
      "epoch =  31\n",
      "Training Avg. Loss: 0.002495, Accuracy: 0.967190\n",
      "Validation Avg. Loss: 0.035125, Accuracy: 0.868726\n",
      "epoch =  32\n",
      "Training Avg. Loss: 0.002002, Accuracy: 0.973915\n",
      "Validation Avg. Loss: 0.032835, Accuracy: 0.876448\n",
      "epoch =  33\n",
      "Training Avg. Loss: 0.002041, Accuracy: 0.974119\n",
      "Validation Avg. Loss: 0.034831, Accuracy: 0.876448\n",
      "epoch =  34\n",
      "Training Avg. Loss: 0.001828, Accuracy: 0.975138\n",
      "Validation Avg. Loss: 0.031610, Accuracy: 0.868726\n",
      "epoch =  35\n",
      "Training Avg. Loss: 0.002268, Accuracy: 0.973303\n",
      "Validation Avg. Loss: 0.038042, Accuracy: 0.880309\n",
      "epoch =  36\n",
      "Training Avg. Loss: 0.002167, Accuracy: 0.973711\n",
      "Validation Avg. Loss: 0.028982, Accuracy: 0.872587\n",
      "epoch =  37\n",
      "Training Avg. Loss: 0.002295, Accuracy: 0.973303\n",
      "Validation Avg. Loss: 0.066773, Accuracy: 0.861004\n",
      "epoch =  38\n",
      "Training Avg. Loss: 0.002512, Accuracy: 0.970450\n",
      "Validation Avg. Loss: 0.034612, Accuracy: 0.861004\n",
      "epoch =  39\n",
      "Training Avg. Loss: 0.002308, Accuracy: 0.974119\n",
      "Validation Avg. Loss: 0.039682, Accuracy: 0.864865\n",
      "epoch =  40\n",
      "Training Avg. Loss: 0.002686, Accuracy: 0.971062\n",
      "Validation Avg. Loss: 0.038724, Accuracy: 0.857143\n",
      "epoch =  41\n",
      "Training Avg. Loss: 0.002277, Accuracy: 0.976564\n",
      "Validation Avg. Loss: 0.036295, Accuracy: 0.884170\n",
      "epoch =  42\n",
      "Training Avg. Loss: 0.002334, Accuracy: 0.974934\n",
      "Validation Avg. Loss: 0.041702, Accuracy: 0.868726\n",
      "epoch =  43\n",
      "Training Avg. Loss: 0.002261, Accuracy: 0.978194\n",
      "Validation Avg. Loss: 0.039607, Accuracy: 0.864865\n",
      "epoch =  44\n",
      "Training Avg. Loss: 0.002199, Accuracy: 0.978398\n",
      "Validation Avg. Loss: 0.036512, Accuracy: 0.891892\n",
      "epoch =  45\n",
      "Training Avg. Loss: 0.001620, Accuracy: 0.981863\n",
      "Validation Avg. Loss: 0.038111, Accuracy: 0.888031\n",
      "epoch =  46\n",
      "Training Avg. Loss: 0.002068, Accuracy: 0.977175\n",
      "Validation Avg. Loss: 0.037522, Accuracy: 0.891892\n",
      "epoch =  47\n",
      "Training Avg. Loss: 0.002356, Accuracy: 0.981047\n",
      "Validation Avg. Loss: 0.038199, Accuracy: 0.911197\n",
      "epoch =  48\n",
      "Training Avg. Loss: 0.002767, Accuracy: 0.976768\n",
      "Validation Avg. Loss: 0.038289, Accuracy: 0.880309\n",
      "epoch =  49\n",
      "Training Avg. Loss: 0.002013, Accuracy: 0.978806\n",
      "Validation Avg. Loss: 0.036237, Accuracy: 0.880309\n",
      "-----------------------------------------\n",
      "Training model 1\n",
      "-----------------------------------------\n",
      "train_size =  2079 valid_size =  110\n",
      "epoch =  0\n",
      "Training Avg. Loss: 0.004887, Accuracy: 0.903800\n",
      "Validation Avg. Loss: 0.005279, Accuracy: 0.890909\n",
      "epoch =  1\n",
      "Training Avg. Loss: 0.003291, Accuracy: 0.926888\n",
      "Validation Avg. Loss: 0.004688, Accuracy: 0.909091\n",
      "epoch =  2\n",
      "Training Avg. Loss: 0.002082, Accuracy: 0.954305\n",
      "Validation Avg. Loss: 0.005277, Accuracy: 0.890909\n",
      "epoch =  3\n",
      "Training Avg. Loss: 0.003852, Accuracy: 0.917268\n",
      "Validation Avg. Loss: 0.005933, Accuracy: 0.890909\n",
      "epoch =  4\n",
      "Training Avg. Loss: 0.001779, Accuracy: 0.962482\n",
      "Validation Avg. Loss: 0.007016, Accuracy: 0.927273\n",
      "epoch =  5\n",
      "Training Avg. Loss: 0.002251, Accuracy: 0.950457\n",
      "Validation Avg. Loss: 0.005529, Accuracy: 0.890909\n",
      "epoch =  6\n",
      "Training Avg. Loss: 0.001543, Accuracy: 0.969697\n",
      "Validation Avg. Loss: 0.007491, Accuracy: 0.918182\n",
      "epoch =  7\n",
      "Training Avg. Loss: 0.001524, Accuracy: 0.968735\n",
      "Validation Avg. Loss: 0.010216, Accuracy: 0.918182\n",
      "epoch =  8\n",
      "Training Avg. Loss: 0.001672, Accuracy: 0.963444\n",
      "Validation Avg. Loss: 0.011615, Accuracy: 0.918182\n",
      "epoch =  9\n",
      "Training Avg. Loss: 0.001633, Accuracy: 0.966811\n",
      "Validation Avg. Loss: 0.012861, Accuracy: 0.936364\n",
      "epoch =  10\n",
      "Training Avg. Loss: 0.000694, Accuracy: 0.985570\n",
      "Validation Avg. Loss: 0.014754, Accuracy: 0.927273\n",
      "epoch =  11\n",
      "Training Avg. Loss: 0.001571, Accuracy: 0.974507\n",
      "Validation Avg. Loss: 0.011943, Accuracy: 0.927273\n",
      "epoch =  12\n",
      "Training Avg. Loss: 0.000563, Accuracy: 0.988937\n",
      "Validation Avg. Loss: 0.012844, Accuracy: 0.918182\n",
      "epoch =  13\n",
      "Training Avg. Loss: 0.001146, Accuracy: 0.981241\n",
      "Validation Avg. Loss: 0.014454, Accuracy: 0.936364\n",
      "epoch =  14\n",
      "Training Avg. Loss: 0.001549, Accuracy: 0.980760\n",
      "Validation Avg. Loss: 0.012805, Accuracy: 0.945455\n",
      "epoch =  15\n",
      "Training Avg. Loss: 0.001257, Accuracy: 0.981722\n",
      "Validation Avg. Loss: 0.018505, Accuracy: 0.909091\n",
      "epoch =  16\n",
      "Training Avg. Loss: 0.000792, Accuracy: 0.987975\n",
      "Validation Avg. Loss: 0.016909, Accuracy: 0.936364\n",
      "epoch =  17\n",
      "Training Avg. Loss: 0.000482, Accuracy: 0.989418\n",
      "Validation Avg. Loss: 0.022134, Accuracy: 0.909091\n",
      "epoch =  18\n",
      "Training Avg. Loss: 0.000579, Accuracy: 0.990380\n",
      "Validation Avg. Loss: 0.021385, Accuracy: 0.945455\n",
      "epoch =  19\n",
      "Training Avg. Loss: 0.001017, Accuracy: 0.987494\n",
      "Validation Avg. Loss: 0.022016, Accuracy: 0.927273\n",
      "epoch =  20\n",
      "Training Avg. Loss: 0.000478, Accuracy: 0.990380\n",
      "Validation Avg. Loss: 0.025078, Accuracy: 0.936364\n",
      "epoch =  21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Avg. Loss: 0.001878, Accuracy: 0.981722\n",
      "Validation Avg. Loss: 0.018236, Accuracy: 0.918182\n",
      "epoch =  22\n",
      "Training Avg. Loss: 0.000943, Accuracy: 0.990380\n",
      "Validation Avg. Loss: 0.026373, Accuracy: 0.927273\n",
      "epoch =  23\n",
      "Training Avg. Loss: 0.001659, Accuracy: 0.984608\n",
      "Validation Avg. Loss: 0.019915, Accuracy: 0.945455\n",
      "epoch =  24\n",
      "Training Avg. Loss: 0.000685, Accuracy: 0.993266\n",
      "Validation Avg. Loss: 0.021277, Accuracy: 0.936364\n",
      "epoch =  25\n",
      "Training Avg. Loss: 0.002628, Accuracy: 0.975469\n",
      "Validation Avg. Loss: 0.043354, Accuracy: 0.918182\n",
      "epoch =  26\n",
      "Training Avg. Loss: 0.000829, Accuracy: 0.991823\n",
      "Validation Avg. Loss: 0.029636, Accuracy: 0.936364\n",
      "epoch =  27\n",
      "Training Avg. Loss: 0.002707, Accuracy: 0.979798\n",
      "Validation Avg. Loss: 0.043997, Accuracy: 0.927273\n",
      "epoch =  28\n",
      "Training Avg. Loss: 0.000945, Accuracy: 0.993266\n",
      "Validation Avg. Loss: 0.035893, Accuracy: 0.945455\n",
      "epoch =  29\n",
      "Training Avg. Loss: 0.000791, Accuracy: 0.991342\n",
      "Validation Avg. Loss: 0.040436, Accuracy: 0.936364\n",
      "epoch =  30\n",
      "Training Avg. Loss: 0.000570, Accuracy: 0.994709\n",
      "Validation Avg. Loss: 0.035821, Accuracy: 0.936364\n",
      "epoch =  31\n",
      "Training Avg. Loss: 0.002123, Accuracy: 0.985570\n",
      "Validation Avg. Loss: 0.032365, Accuracy: 0.927273\n",
      "epoch =  32\n",
      "Training Avg. Loss: 0.000815, Accuracy: 0.992785\n",
      "Validation Avg. Loss: 0.030180, Accuracy: 0.936364\n",
      "epoch =  33\n",
      "Training Avg. Loss: 0.002834, Accuracy: 0.977393\n",
      "Validation Avg. Loss: 0.030360, Accuracy: 0.936364\n",
      "epoch =  34\n",
      "Training Avg. Loss: 0.000299, Accuracy: 0.995671\n",
      "Validation Avg. Loss: 0.032226, Accuracy: 0.954545\n",
      "epoch =  35\n",
      "Training Avg. Loss: 0.000785, Accuracy: 0.993747\n",
      "Validation Avg. Loss: 0.035132, Accuracy: 0.954545\n",
      "epoch =  36\n",
      "Training Avg. Loss: 0.000404, Accuracy: 0.995190\n",
      "Validation Avg. Loss: 0.041142, Accuracy: 0.927273\n",
      "epoch =  37\n",
      "Training Avg. Loss: 0.000835, Accuracy: 0.991342\n",
      "Validation Avg. Loss: 0.041135, Accuracy: 0.936364\n",
      "epoch =  38\n",
      "Training Avg. Loss: 0.000362, Accuracy: 0.994228\n",
      "Validation Avg. Loss: 0.036680, Accuracy: 0.918182\n",
      "epoch =  39\n",
      "Training Avg. Loss: 0.000708, Accuracy: 0.993266\n",
      "Validation Avg. Loss: 0.039815, Accuracy: 0.936364\n",
      "epoch =  40\n",
      "Training Avg. Loss: 0.001142, Accuracy: 0.991342\n",
      "Validation Avg. Loss: 0.025423, Accuracy: 0.936364\n",
      "epoch =  41\n",
      "Training Avg. Loss: 0.000869, Accuracy: 0.993747\n",
      "Validation Avg. Loss: 0.043373, Accuracy: 0.918182\n",
      "epoch =  42\n",
      "Training Avg. Loss: 0.000778, Accuracy: 0.992304\n",
      "Validation Avg. Loss: 0.024294, Accuracy: 0.927273\n",
      "epoch =  43\n",
      "Training Avg. Loss: 0.001430, Accuracy: 0.988937\n",
      "Validation Avg. Loss: 0.039330, Accuracy: 0.936364\n",
      "epoch =  44\n",
      "Training Avg. Loss: 0.000537, Accuracy: 0.995671\n",
      "Validation Avg. Loss: 0.052548, Accuracy: 0.945455\n",
      "epoch =  45\n",
      "Training Avg. Loss: 0.001470, Accuracy: 0.989899\n",
      "Validation Avg. Loss: 0.048851, Accuracy: 0.927273\n",
      "epoch =  46\n",
      "Training Avg. Loss: 0.001270, Accuracy: 0.992785\n",
      "Validation Avg. Loss: 0.066582, Accuracy: 0.918182\n",
      "epoch =  47\n",
      "Training Avg. Loss: 0.000309, Accuracy: 0.996633\n",
      "Validation Avg. Loss: 0.048140, Accuracy: 0.927273\n",
      "epoch =  48\n",
      "Training Avg. Loss: 0.000958, Accuracy: 0.993266\n",
      "Validation Avg. Loss: 0.052557, Accuracy: 0.936364\n",
      "epoch =  49\n",
      "Training Avg. Loss: 0.000814, Accuracy: 0.992304\n",
      "Validation Avg. Loss: 0.057396, Accuracy: 0.945455\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Training model %d\" % i)\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    net = MyModule(_input_size, 15 if i == 0 else 13)\n",
    "    best_acc = 0\n",
    "\n",
    "    train_size = int(0.95 * len(DS2[i]))\n",
    "    valid_size = len(DS2[i]) - train_size\n",
    "    print(\"train_size = \", train_size, \"valid_size = \", valid_size)\n",
    "\n",
    "    train_data, valid_data = torch.utils.data.random_split(DS2[i], [train_size, valid_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 64)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = 64)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        print(\"epoch = \", epoch)\n",
    "        train(net, data_loader = train_loader,\n",
    "               data_size = train_size,\n",
    "               criterion = nn.CrossEntropyLoss(),\n",
    "               optimizer = optim.Adam(net.parameters(), lr = 0.01))\n",
    "        validate(net, data_loader = valid_loader,\n",
    "                  data_size = valid_size,\n",
    "                  criterion = nn.CrossEntropyLoss(),\n",
    "                  model_name = str(i) + \"bywings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"USER\", \"\") == \"root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"requests\":[{\"own\":[34,48,26,6,46,37,51,36,1,27,17,5,24,29,18,52,53],\"bid\":[0,0]},{\"history\":[[7,9,10,11],[4,32,33,35]],\"own\":[34,48,26,6,46,37,51,36,1,27,17,5,24,29,18,52,53],\"publiccard\":[39,0,9],\"landlord\":0,\"pos\":2,\"finalbid\":1},{\"history\":[[0,44,45,47],[]]},{\"history\":[[],[]]}],\"responses\":[0,[],[52,53]]}\n",
      "{\"response\": [26, 27, 24, 1]}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5de24e9ba574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mBIDDING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mPLAYING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-5de24e9ba574>\u001b[0m in \u001b[0;36mPLAYING\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     }))\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_BOTZONE_ONLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_BOTZONE_ONLINE = os.environ.get(\"USER\", \"\") == \"root\"\n",
    "\n",
    "my_hand = []\n",
    "g = Game([[], [], []])\n",
    "my_pos = -1\n",
    "others = []\n",
    "combos = [(0, 0, 0, 0), (0, 0, 0, 0), (0, 0, 0, 0)]\n",
    "las_combo = (0, 0, 0, 0)\n",
    "\n",
    "def BIDDING():\n",
    "    bid_val = 0\n",
    "    print(json.dumps({\n",
    "        \"response\": bid_val\n",
    "    }))\n",
    "    if not _BOTZONE_ONLINE:\n",
    "        assert(0)\n",
    "    exit()\n",
    "\n",
    "model_path = \"./data/fightlandlord_model/\" if _BOTZONE_ONLINE else \"./model/\"\n",
    "\n",
    "def PLAYING():\n",
    "    def getFromHand(idx):\n",
    "        global my_hand\n",
    "        for c in my_hand:\n",
    "            if getCardId(c) == idx:\n",
    "                my_hand.remove(c)\n",
    "                return c\n",
    "    \n",
    "    to_play = []\n",
    "        \n",
    "    model_name = \"best_model_for_\" + str(my_pos) + \"mainbody.pt\"\n",
    "    model = torch.load(model_path + model_name)\n",
    "    \n",
    "    mask = g.getMask1(my_pos, las_combo)\n",
    "    combo_id = -1\n",
    "    if np.sum(mask) == 1:\n",
    "        combo_id = np.argmax(mask)\n",
    "    else:\n",
    "        combo_id = model(torch.from_numpy(g.getInput(my_pos, combos)).unsqueeze(0),\n",
    "                         torch.from_numpy(mask)).unsqueeze(0).detach().numpy().argmax()\n",
    "    \n",
    "    combo = combo_list[combo_id]\n",
    "    for i in range(combo[1], combo[2] + 1):\n",
    "        for j in range(combo[0]):\n",
    "            to_play.append(getFromHand(i))\n",
    "    g.play(my_pos, to_play)\n",
    "    \n",
    "    if combo[3] != 0:\n",
    "        model_name = \"best_model_for_\" + str(combo[3] - 1) + \"bywings.pt\"\n",
    "        model = torch.load(model_path + model_name)\n",
    "\n",
    "        cnt = (combo[2] - combo[1] + 1) * (1 if combo[0] == 3 else 2)\n",
    "        already_played = []\n",
    "        for i in range(cnt):\n",
    "            wing_id = model(torch.from_numpy(g.getInput(my_pos, combos)),\n",
    "                            torch.from_numpy(g.getMask2(my_pos, combo, already_played))).detach().numpy().argmax()\n",
    "            tmp = []\n",
    "            if wing_id < 15:\n",
    "                tmp = [getFromHand(wing_id)]\n",
    "            else:\n",
    "                wing_id -= 15\n",
    "                tmp = [getFromHand(wing_id), getFromHand(wing_id)]\n",
    "            g.play(my_pos, tmp)\n",
    "            to_play.extend(tmp)\n",
    "            already_played.append(wing_id)\n",
    "    \n",
    "    print(json.dumps({\n",
    "        \"response\": to_play\n",
    "    }))\n",
    "    if not _BOTZONE_ONLINE:\n",
    "        assert 0\n",
    "    exit()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    initCombo()\n",
    "    data = json.loads(input())\n",
    "    my_hand, others_hand = data[\"requests\"][0][\"own\"], []\n",
    "    for i in range(54):\n",
    "        if i not in my_hand:\n",
    "            others_hand.append(i)\n",
    "\n",
    "    TODO = \"bidding\"\n",
    "    if \"bid\" in data[\"requests\"][0]:\n",
    "        bid_list = data[\"requests\"][0][\"bid\"]\n",
    "    \n",
    "    for i in range(len(data[\"requests\"])):\n",
    "        request = data[\"requests\"][i]\n",
    "        \n",
    "        if \"publiccard\" in request:\n",
    "            bot_pos = request[\"pos\"]\n",
    "            lord_pos = request[\"landlord\"]\n",
    "            my_pos = (bot_pos - lord_pos + 3) % 3\n",
    "            others = [(my_pos + 1) % 3, (my_pos + 2) % 3]\n",
    "            tmp = [[], [], []]\n",
    "            if my_pos == 0:\n",
    "                my_hand.extend(request[\"publiccard\"])\n",
    "                tmp[0] = my_hand\n",
    "                tmp[1], tmp[2] = others_hand[:17], others_hand[17:] # 随便分\n",
    "            else:\n",
    "                tmp[my_pos] = my_hand\n",
    "                tmp[0] = others_hand[:20]\n",
    "                tmp[2 if my_pos == 1 else 1] = others_hand[20:]\n",
    "            g = Game(tmp)\n",
    "            \n",
    "        if \"history\" in request:\n",
    "            history = request[\"history\"]\n",
    "            TODO = \"playing\"\n",
    "            for j in range(2):\n",
    "                p = others[j]\n",
    "                cards = history[j]\n",
    "                g.play(p, cards)\n",
    "                combos[p] = getCombo(cards)\n",
    "\n",
    "            if i < len(data[\"requests\"]) - 1:\n",
    "                cards = data[\"responses\"][i]\n",
    "                g.play(my_pos, cards)\n",
    "                for c in cards:\n",
    "                    my_hand.remove(c)\n",
    "                combos[my_pos] = getCombo(cards)\n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        if combos[(my_pos + i) % 3] != (0, 0, 0, 0):\n",
    "            las_combo = combos[(my_pos + i) % 3]\n",
    "\n",
    "    if TODO == \"bidding\":\n",
    "        BIDDING()\n",
    "    else:\n",
    "        PLAYING()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0abe24cc2c85471f8bfda881bfeb331aa7f1aab4cc08a91b6e74430d18329c90e",
   "display_name": "Python 3.7.10 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}