{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入(这段读的是aigame作业的下发json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json = []\n",
    "\n",
    "aigame_botid = [\"6048fc6b81fb3b738e911e3b\",\n",
    "               \"6048fcf381fb3b738e912cb8\",\n",
    "               \"6048fd3781fb3b738e9138ac\",\n",
    "               \"6048fd7981fb3b738e9140fc\",\n",
    "               \"6048fda981fb3b738e914488\"]\n",
    "\n",
    "def get_all_json(cwd):\n",
    "    get_dir = os.listdir(cwd)  \n",
    "    for i in get_dir:          \n",
    "        sub_dir = os.path.join(cwd,i)  \n",
    "        if os.path.isdir(sub_dir):     \n",
    "            get_all_json(sub_dir)\n",
    "        else:\n",
    "            if i[-5:] == \".json\":\n",
    "                all_json.append(cwd + \"/\" + i)\n",
    "                \n",
    "get_all_json(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入(这段读的是botzone上下载的对局数据，nb_bots是天梯上排名前30的botid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = []\n",
    "\n",
    "def get_all_matches(cwd):\n",
    "    get_dir = os.listdir(cwd)  \n",
    "    for i in get_dir:          \n",
    "        sub_dir = os.path.join(cwd,i)  \n",
    "        if os.path.isdir(sub_dir):\n",
    "            get_all_matches(sub_dir)\n",
    "        else:\n",
    "            if i[-8:] == \".matches\":\n",
    "                all_matches.append(cwd + \"/\" + i)\n",
    "\n",
    "get_all_matches(\"data/\")\n",
    "nb_bots = open(\"nbbot.txt\", \"r+\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理 Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCardId(card):\n",
    "    # 求一张牌的 id\n",
    "    if card < 52:\n",
    "        return card // 4\n",
    "    else:\n",
    "        return card - 39\n",
    "\n",
    "def getCombo(cards):\n",
    "    # a combo is represented as a tuple(k, l, r, w)\n",
    "    # 表示有 k * [l, r] 即 k 张 [l, r] 中的牌（作为主体）w \\in [0, 1, 2] 表示带的是啥类型\n",
    "    if len(cards) == 0:\n",
    "        return (0, 0, 0, 0)\n",
    "    tmp = np.zeros(15, dtype = int)\n",
    "    for card in cards:\n",
    "        tmp[getCardId(card)] += 1\n",
    "    k = np.max(tmp)\n",
    "    l = np.min(np.where(tmp == k))\n",
    "    r = np.max(np.where(tmp == k))\n",
    "    w = 0\n",
    "    if k == 3:\n",
    "        w = len(cards) // (r - l + 1) - 3\n",
    "    if k == 4:\n",
    "        w = (len(cards) // (r - l + 1) - 4) // 2\n",
    "    return (k, l, r, w)\n",
    "\n",
    "combo_dict = {}\n",
    "combo_list = []\n",
    "combo_cnt = 0\n",
    "\n",
    "def initCombo():\n",
    "    global combo_dict, combo_list, combo_cnt\n",
    "    combo_dict = {}\n",
    "    combo_list = []\n",
    "    combo_cnt = 0\n",
    "    def addCombo(combo):\n",
    "        global combo_dict, combo_list, combo_cnt\n",
    "        combo_list.append(combo)\n",
    "        combo_dict[combo] = combo_cnt\n",
    "        combo_cnt += 1\n",
    "\n",
    "    minLength = [0, 5, 3, 2, 2]\n",
    "    maxWings = [0, 1, 1, 3, 3]\n",
    "    fold = [0, 0, 0, 1, 2]\n",
    "    for k in range(1, 5):\n",
    "        for x in range(13):\n",
    "            for w in range(maxWings[k]):\n",
    "                addCombo((k, x, x, w))\n",
    "        for l in range(12):\n",
    "            for r in range(l + minLength[k] - 1, 12):\n",
    "                for w in range(maxWings[k]):\n",
    "                    if (r - l + 1) * (k + w * fold[k]) <= 20:\n",
    "                        addCombo((k, l, r, w))\n",
    "    addCombo((1, 13, 13, 0))\n",
    "    addCombo((1, 14, 14, 0))\n",
    "    addCombo((1, 13, 14, 0))\n",
    "    addCombo((0, 0, 0, 0))\n",
    "    \n",
    "initCombo()\n",
    "\n",
    "def getPartition(cards):\n",
    "    # 把一次出牌的编号集合划分成 mainbody 和 bywings\n",
    "    # 其中 mainbody 是一个 list ，bywings 中每个 wing 是一个 list ，也就是一个 list 的 list\n",
    "    combo = getCombo(cards)\n",
    "    tmp = [[] for i in range(15)]\n",
    "    for card in cards:\n",
    "        tmp[getCardId(card)].append(card)\n",
    "    mainbody, bywings = [], []\n",
    "    for i in range(15):\n",
    "        if len(tmp[i]) > 0:\n",
    "            if combo[1] <= i and i <= combo[2]:\n",
    "                mainbody.extend(tmp[i])\n",
    "            else:\n",
    "                bywings.append(tmp[i])\n",
    "    return mainbody, bywings\n",
    "\n",
    "def getComboMask(combo):\n",
    "    # 给出一个 combo ，返回可以接在其后面牌型 mask \n",
    "    mask = np.zeros(combo_cnt)\n",
    "    if combo == (0, 0, 0, 0):\n",
    "        mask = np.ones(combo_cnt)\n",
    "        mask[combo_dict[(0, 0, 0, 0)]] = 0\n",
    "        return mask\n",
    "    mask[combo_dict[(0, 0, 0, 0)]] = 1\n",
    "\n",
    "    if combo == (1, 13, 14, 0):\n",
    "        return mask\n",
    "    mask[combo_dict[(1, 13, 14, 0)]] = 1\n",
    "\n",
    "    if combo[0] == 4 and combo[1] == combo[2] and combo[3] == 0:\n",
    "        for i in range(combo[1] + 1, 13):\n",
    "            mask[combo_dict[(4, i, i, 0)]] = 1\n",
    "        return mask\n",
    "    for i in range(13):\n",
    "        mask[combo_dict[(4, i, i, 0)]] = 1\n",
    "\n",
    "    for cb in combo_list:\n",
    "        if cb[0] == combo[0] and cb[2] - cb[1] == combo[2] - combo[1] and cb[3] == combo[3] and cb[1] > combo[1]:\n",
    "            mask[combo_dict[cb]] = 1\n",
    "            \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    # 这里 0 始终是地主，1 始终是地主下家，2 始终是地主上家\n",
    "\n",
    "    def __init__(self, init_data):\n",
    "        self.hand = [np.zeros(15, dtype = int), np.zeros(15, dtype = int), np.zeros(15, dtype = int)]\n",
    "        for player in range(3):\n",
    "            for card in init_data[player]:\n",
    "                self.hand[player][getCardId(card)] += 1\n",
    "    \n",
    "    def play(self, player, cards):\n",
    "        # 模拟打牌 打出 cards 这个 list 中的所有牌\n",
    "        for card in cards:\n",
    "            self.hand[player][getCardId(card)] -= 1\n",
    "            \n",
    "    def possess(self, player, combo):\n",
    "        # 判断 player 这个玩家是否拥有 combo 这个牌型的牌\n",
    "        if combo == (0, 0, 0, 0):\n",
    "            return True\n",
    "        for i in range(combo[1], combo[2] + 1):\n",
    "            if self.hand[player][i] < combo[0]:\n",
    "                return False\n",
    "            \n",
    "        fold = [0, 0, 0, 1, 2]\n",
    "        need_wings = (combo[2] - combo[1] + 1) * fold[combo[0]] if combo[3] > 0 else 0\n",
    "        for i in range(15):\n",
    "            if i < combo[1] or i > combo[2]:\n",
    "                if self.hand[player][i] >= combo[3]:\n",
    "                    need_wings -= 1\n",
    "        if need_wings > 0:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def getPossessMask(self, player):\n",
    "        # 返回 player 拥有的牌型 mask\n",
    "        mask = np.zeros(combo_cnt)\n",
    "        for i in range(combo_cnt):\n",
    "            if self.possess(player, combo_list[i]) == True:\n",
    "                mask[i] = 1\n",
    "        return mask\n",
    "    \n",
    "    def getMask1(self, player, combo):\n",
    "        # getPossessMask 和 getComboMask 取交集\n",
    "        return self.getPossessMask(player) * getComboMask(combo)\n",
    "    \n",
    "    def getMask2(self, player, combo, already_played):\n",
    "        # 带翼的 mask，哪些翼是可以打的？\n",
    "        # mask 的大小是 28, 表示 15 种单牌和 13 种对子\n",
    "        # 指明 combo 后：(1)单牌/对子不能错 (2)少于1/2张的不能打 (3)和主体部分重复的不能打 (4)打过的不能打\n",
    "        mask = np.ones(28)\n",
    "        if combo[3] == 1:\n",
    "            mask[range(15, 28)] = 0\n",
    "            for i in range(13):\n",
    "                if self.hand[player][i] < 1:\n",
    "                    mask[i] = 0\n",
    "            mask[range(combo[1], combo[2] + 1)] = 0\n",
    "            for i in already_played:\n",
    "                mask[i] = 0\n",
    "        else:\n",
    "            assert combo[3] == 2\n",
    "            mask[range(0, 15)] = 0\n",
    "            for i in range(13):\n",
    "                if self.hand[player][i] < 2:\n",
    "                    mask[i + 15] = 0\n",
    "            mask[range(combo[1] + 15, combo[2] + 16)] = 0\n",
    "            for i in already_played:\n",
    "                mask[i + 15] = 0\n",
    "        return mask\n",
    "    \n",
    "    def getInput(self, player):\n",
    "        # 返回两个网络的输入\n",
    "        # 这里包含五个部分：我自己的手牌数、对手的手牌数、我的顺子情况、三个人还剩多少张牌、我拥有牌型的 mask\n",
    "        # size = 4 * 15 + 4 * 15 + 4 * 12 + 3 * 20 + 379\n",
    "        p1 = (player + 1) % 3\n",
    "        p2 = (player + 2) % 3\n",
    "\n",
    "        myhand = np.zeros((4, 15))\n",
    "        othershand = np.zeros((4, 15))\n",
    "        for i in range(4):\n",
    "            myhand[i, np.where(self.hand[player] >= i + 1)] = 1\n",
    "            othershand[i, np.where(self.hand[p1] + self.hand[p2] >= i + 1)] = 1\n",
    "        \n",
    "        mystraight = np.zeros((4, 12))\n",
    "        for i in range(4):\n",
    "            k = 0\n",
    "            for j in range(12):\n",
    "                if self.hand[player][i] >= i + 1:\n",
    "                    k += 1\n",
    "                else:\n",
    "                    k = 0\n",
    "                mystraight[i, j] = k\n",
    "                \n",
    "        handcnt = np.zeros((3, 20))\n",
    "        for player in range(3):\n",
    "            handcnt[player, range(np.sum(self.hand[player]))] = 1\n",
    "\n",
    "        return np.concatenate([myhand.flatten(), othershand.flatten(), mystraight.flatten(), handcnt.flatten(), self.getPossessMask(player)])\n",
    "    \n",
    "_input_size = 60 + 60 + 48 + 60 + combo_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = []\n",
    "        self.M = []\n",
    "        self.Y = []\n",
    "    def append(self, x, m, y):\n",
    "        self.X.append(x)\n",
    "        self.M.append(m)\n",
    "        self.Y.append(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.M[idx], self.Y[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS1 = [MyDataset(), MyDataset(), MyDataset()]\n",
    "DS2 = MyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_20.json\n",
      "files = 1, lengths = (1169, 1007, 1146, 165, 113, 113)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_16.json\n",
      "files = 2, lengths = (2152, 1807, 2007, 303, 206, 196)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_10.json\n",
      "files = 3, lengths = (2840, 2408, 2573, 391, 277, 260)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_3.json\n",
      "files = 4, lengths = (3087, 2607, 2796, 427, 296, 277)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_4.json\n",
      "files = 5, lengths = (3697, 3108, 3290, 520, 342, 323)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_5.json\n",
      "files = 6, lengths = (4058, 3396, 3581, 580, 380, 348)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_22.json\n",
      "files = 7, lengths = (5064, 4317, 4569, 733, 479, 430)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_21.json\n",
      "files = 8, lengths = (6193, 5322, 5638, 920, 589, 529)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_23.json\n",
      "files = 9, lengths = (7478, 6383, 6757, 1088, 693, 643)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_27.json\n",
      "files = 10, lengths = (7893, 6688, 7102, 1143, 727, 679)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_1.json\n",
      "files = 11, lengths = (8128, 6883, 7313, 1192, 754, 698)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_7.json\n",
      "files = 12, lengths = (8609, 7248, 7699, 1263, 788, 743)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_18.json\n",
      "files = 13, lengths = (9770, 8224, 8731, 1427, 899, 846)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_28.json\n",
      "files = 14, lengths = (14058, 11834, 12516, 2085, 1270, 1219)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_25.json\n",
      "files = 15, lengths = (15536, 12988, 13720, 2304, 1401, 1328)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_8.json\n",
      "files = 16, lengths = (16181, 13551, 14324, 2410, 1465, 1381)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_26.json\n",
      "files = 17, lengths = (16812, 14028, 14890, 2503, 1517, 1421)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_13.json\n",
      "files = 18, lengths = (17313, 14431, 15317, 2584, 1555, 1447)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_15.json\n",
      "files = 19, lengths = (18173, 15181, 16095, 2700, 1636, 1517)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_6.json\n",
      "files = 20, lengths = (18705, 15646, 16563, 2794, 1682, 1559)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_17.json\n",
      "files = 21, lengths = (19723, 16543, 17483, 2947, 1766, 1653)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_24.json\n",
      "files = 22, lengths = (20602, 17270, 18295, 3075, 1846, 1725)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_11.json\n",
      "files = 23, lengths = (21045, 17634, 18681, 3135, 1886, 1776)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_9.json\n",
      "files = 24, lengths = (21759, 18254, 19341, 3229, 1949, 1832)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_19.json\n",
      "files = 25, lengths = (22646, 19022, 20148, 3355, 2029, 1892)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_2.json\n",
      "files = 26, lengths = (22927, 19274, 20418, 3410, 2053, 1924)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_12.json\n",
      "files = 27, lengths = (23277, 19575, 20697, 3457, 2091, 1945)\n",
      "data/download_bot_matches/1_6048fc6b81fb3b738e911e3b/train/log_1_14.json\n",
      "files = 28, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_1.json\n",
      "files = 29, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_19.json\n",
      "files = 30, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_10.json\n",
      "files = 31, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_29.json\n",
      "files = 32, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_18.json\n",
      "files = 33, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_35.json\n",
      "files = 34, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_31.json\n",
      "files = 35, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_3.json\n",
      "files = 36, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_22.json\n",
      "files = 37, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_28.json\n",
      "files = 38, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_2.json\n",
      "files = 39, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_24.json\n",
      "files = 40, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_33.json\n",
      "files = 41, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_12.json\n",
      "files = 42, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_21.json\n",
      "files = 43, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_7.json\n",
      "files = 44, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_37.json\n",
      "files = 45, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_25.json\n",
      "files = 46, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_20.json\n",
      "files = 47, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_13.json\n",
      "files = 48, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_36.json\n",
      "files = 49, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_11.json\n",
      "files = 50, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_32.json\n",
      "files = 51, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_5.json\n",
      "files = 52, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_6.json\n",
      "files = 53, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_15.json\n",
      "files = 54, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_4.json\n",
      "files = 55, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_8.json\n",
      "files = 56, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_26.json\n",
      "files = 57, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_14.json\n",
      "files = 58, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_34.json\n",
      "files = 59, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_9.json\n",
      "files = 60, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_30.json\n",
      "files = 61, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_38.json\n",
      "files = 62, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_17.json\n",
      "files = 63, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_27.json\n",
      "files = 64, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_16.json\n",
      "files = 65, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/4_6048fd7981fb3b738e9140fc/train/log_4_23.json\n",
      "files = 66, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_16.json\n",
      "files = 67, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_37.json\n",
      "files = 68, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_38.json\n",
      "files = 69, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_14.json\n",
      "files = 70, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_35.json\n",
      "files = 71, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_3.json\n",
      "files = 72, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_28.json\n",
      "files = 73, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_20.json\n",
      "files = 74, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_19.json\n",
      "files = 75, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_23.json\n",
      "files = 76, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_21.json\n",
      "files = 77, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_2.json\n",
      "files = 78, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_8.json\n",
      "files = 79, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_10.json\n",
      "files = 80, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_9.json\n",
      "files = 81, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_36.json\n",
      "files = 82, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_29.json\n",
      "files = 83, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_11.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files = 84, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_13.json\n",
      "files = 85, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_5.json\n",
      "files = 86, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_18.json\n",
      "files = 87, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_12.json\n",
      "files = 88, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_31.json\n",
      "files = 89, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_26.json\n",
      "files = 90, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_27.json\n",
      "files = 91, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_1.json\n",
      "files = 92, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_15.json\n",
      "files = 93, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_24.json\n",
      "files = 94, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_7.json\n",
      "files = 95, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_4.json\n",
      "files = 96, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_32.json\n",
      "files = 97, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_25.json\n",
      "files = 98, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_17.json\n",
      "files = 99, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_6.json\n",
      "files = 100, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_30.json\n",
      "files = 101, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_33.json\n",
      "files = 102, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_34.json\n",
      "files = 103, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/2_6048fcf381fb3b738e912cb8/train/log_2_22.json\n",
      "files = 104, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_9.json\n",
      "files = 105, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_20.json\n",
      "files = 106, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_22.json\n",
      "files = 107, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_34.json\n",
      "files = 108, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_31.json\n",
      "files = 109, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_32.json\n",
      "files = 110, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_35.json\n",
      "files = 111, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_17.json\n",
      "files = 112, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_11.json\n",
      "files = 113, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_25.json\n",
      "files = 114, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_6.json\n",
      "files = 115, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_8.json\n",
      "files = 116, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_7.json\n",
      "files = 117, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_28.json\n",
      "files = 118, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_2.json\n",
      "files = 119, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_19.json\n",
      "files = 120, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_21.json\n",
      "files = 121, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_18.json\n",
      "files = 122, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_16.json\n",
      "files = 123, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_12.json\n",
      "files = 124, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_14.json\n",
      "files = 125, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_4.json\n",
      "files = 126, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_26.json\n",
      "files = 127, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_13.json\n",
      "files = 128, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_3.json\n",
      "files = 129, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_1.json\n",
      "files = 130, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_27.json\n",
      "files = 131, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_30.json\n",
      "files = 132, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_38.json\n",
      "files = 133, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_33.json\n",
      "files = 134, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_36.json\n",
      "files = 135, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_37.json\n",
      "files = 136, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_23.json\n",
      "files = 137, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_15.json\n",
      "files = 138, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_10.json\n",
      "files = 139, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_5.json\n",
      "files = 140, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/5_6048fda981fb3b738e914488/train/log_5_24.json\n",
      "files = 141, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_33.json\n",
      "files = 142, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_11.json\n",
      "files = 143, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_1.json\n",
      "files = 144, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_19.json\n",
      "files = 145, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_7.json\n",
      "files = 146, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_32.json\n",
      "files = 147, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_21.json\n",
      "files = 148, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_5.json\n",
      "files = 149, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_3.json\n",
      "files = 150, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_20.json\n",
      "files = 151, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_23.json\n",
      "files = 152, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_2.json\n",
      "files = 153, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_16.json\n",
      "files = 154, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_27.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files = 155, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_17.json\n",
      "files = 156, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_10.json\n",
      "files = 157, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_34.json\n",
      "files = 158, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_31.json\n",
      "files = 159, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_22.json\n",
      "files = 160, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_13.json\n",
      "files = 161, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_30.json\n",
      "files = 162, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_15.json\n",
      "files = 163, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_29.json\n",
      "files = 164, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_6.json\n",
      "files = 165, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_28.json\n",
      "files = 166, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_25.json\n",
      "files = 167, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_18.json\n",
      "files = 168, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_26.json\n",
      "files = 169, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_8.json\n",
      "files = 170, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_4.json\n",
      "files = 171, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_37.json\n",
      "files = 172, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_36.json\n",
      "files = 173, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_9.json\n",
      "files = 174, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_24.json\n",
      "files = 175, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_12.json\n",
      "files = 176, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n",
      "data/download_bot_matches/3_6048fd3781fb3b738e9138ac/train/log_3_14.json\n",
      "files = 177, lengths = (23785, 20027, 21129, 3529, 2143, 1982)\n"
     ]
    }
   ],
   "source": [
    "print_cnt = 0\n",
    "\n",
    "for file in all_json:\n",
    "    print(file)\n",
    "    with open(file, 'r+') as f:\n",
    "        while True:\n",
    "            data = f.readline()\n",
    "            if(len(data) == 0):\n",
    "                break\n",
    "            data = json.loads(data)\n",
    "            initdata = json.loads(data['initdata'])\n",
    "\n",
    "            nb_bot = [0, 0, 0]\n",
    "            exists_nb = 0\n",
    "            for i in range(3):\n",
    "                if \"bot\" in data['players'][i].keys() and data['players'][i]['bot'] == aigame_botid[0]:\n",
    "                    nb_bot[i] = 1\n",
    "                    exists_nb = 1\n",
    "            if exists_nb == 0:\n",
    "                break\n",
    "\n",
    "            g = Game(initdata['allocation'])\n",
    "            log = data['log']\n",
    "            \n",
    "            las_combo = (0, 0, 0, 0)\n",
    "            las_play = -1\n",
    "            \n",
    "            for i in range(1, len(log), 2):\n",
    "                player = -1\n",
    "                for p in range(3):\n",
    "                    if str(p) in log[i]:\n",
    "                        player = p\n",
    "                        break\n",
    "                \n",
    "                if log[i][str(p)]['verdict'] != 'OK':\n",
    "                    print(log[i][str(p)]['verdict'])\n",
    "                    break\n",
    "\n",
    "                if las_play == player:\n",
    "                    las_combo = (0, 0, 0, 0)\n",
    "                    \n",
    "                cards = log[i][str(player)]['response']\n",
    "                cur_combo = getCombo(cards)\n",
    "                mainbody, bywings = getPartition(cards)\n",
    "                    \n",
    "                if nb_bot[player]:\n",
    "                    input_x = g.getInput(player)\n",
    "                    input_m = g.getMask1(player, las_combo)\n",
    "                    output_y = combo_dict[cur_combo]\n",
    "                    assert input_m[output_y] == 1\n",
    "                    if np.sum(input_m) > 1:\n",
    "                        DS1[player].append(input_x, input_m, output_y)\n",
    "                \n",
    "                g.play(player, mainbody)\n",
    "                \n",
    "                if len(bywings) != 0:\n",
    "                    already_played = []\n",
    "                    for w in bywings:\n",
    "                        assert len(w) == 1 or len(w) == 2\n",
    "                        if nb_bot[player]:\n",
    "                            input_x = g.getInput(player)\n",
    "                            input_m = g.getMask2(player, cur_combo, already_played)\n",
    "                            output_y = getCardId(w[0]) + (0 if len(w) == 1 else 15)\n",
    "                            if input_m[output_y] != 1:\n",
    "                                print(cards)\n",
    "                                print(mainbody, bywings)\n",
    "                                print(cur_combo)\n",
    "                                print(g.hand[player])\n",
    "                                print(already_played)\n",
    "                                assert 0\n",
    "                            assert input_m[output_y] == 1\n",
    "                            DS.append(input_x, input_m, output_y)\n",
    "                            \n",
    "                        g.play(player, w)\n",
    "                        already_played.append(getCardId(w[0]))\n",
    "                \n",
    "                if cur_combo != (0, 0, 0, 0):\n",
    "                    las_combo = cur_combo\n",
    "                    las_play = player\n",
    "                    \n",
    "                \n",
    "    \n",
    "    print_cnt += 1\n",
    "    print(\"files = %d, lengths = (%d, %d, %d, %d, %d, %d)\"\n",
    "          % (print_cnt, len(DS1[0]), len(DS1[1]), len(DS1[2]), len(DS2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23785 20027 21129\n",
      "3529 2143 1982\n"
     ]
    }
   ],
   "source": [
    "print(len(DS1[0]), len(DS1[1]), len(DS1[2]), len(DS2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 512\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, INPUT_SIZE, OUTPUT_SIZE):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "                ('fc1', nn.Linear(INPUT_SIZE, HIDDEN_SIZE)),\n",
    "                ('relu', nn.ReLU()),\n",
    "                ('bn', nn.BatchNorm1d(HIDDEN_SIZE)),\n",
    "                ('dropout', nn.Dropout(p = 0.1)),\n",
    "                ('fc2', nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)),\n",
    "            ]))\n",
    "        \n",
    "    def forward(self, x, m):\n",
    "        return nn.Softmax(dim = -1)(self.fc(x) * m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练（主体）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "def getPred(output):\n",
    "    return output.detach().numpy().argmax(axis = 1)\n",
    "\n",
    "def train(net, data_loader, data_size, criterion, optimizer):\n",
    "    net.train()\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(x, m)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        output = net(x, m)\n",
    "        avg_loss += criterion(output, y).sum()\n",
    "        pred = getPred(output)\n",
    "        total_correct += (pred == y.detach().numpy()).sum()\n",
    "    avg_loss /= data_size\n",
    "    cur_acc = float(total_correct) / data_size\n",
    "    print('Training Avg. Loss: %f, Accuracy: %f' % (avg_loss, cur_acc))\n",
    "\n",
    "def validate(net, data_loader, data_size, criterion, model_name):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (x, m, y) in enumerate(data_loader):\n",
    "        output = net(x, m)\n",
    "        avg_loss += criterion(output, y).sum()\n",
    "        pred = getPred(output)\n",
    "        total_correct += (pred == y.detach().numpy()).sum()\n",
    "    \n",
    "    avg_loss /= data_size\n",
    "    cur_acc = float(total_correct) / data_size\n",
    "    print('Validation Avg. Loss: %f, Accuracy: %f' % (avg_loss, cur_acc))\n",
    "    \n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        torch.save(net.state_dict(), './model/best_model_for_' + model_name + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Training model 0\n",
      "-----------------------------------------\n",
      "epoch =  0\n",
      "Training Avg. Loss: 0.042377, Accuracy: 0.553910\n",
      "Validation Avg. Loss: 0.043064, Accuracy: 0.563262\n",
      "epoch =  1\n",
      "Training Avg. Loss: 0.042219, Accuracy: 0.568859\n",
      "Validation Avg. Loss: 0.042934, Accuracy: 0.576293\n",
      "epoch =  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-184b15b6dbd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         train(net, data_loader = train_loader,\n\u001b[0m\u001b[1;32m     21\u001b[0m               \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-d9d9853f17ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data_loader, data_size, criterion, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "        \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Training model %d\" % i)\n",
    "    print(\"-----------------------------------------\")\n",
    "\n",
    "    net = MyModule(_input_size, combo_cnt)\n",
    "    best_acc = 0\n",
    "    \n",
    "    train_size = int(0.9 * len(DS1[i]))\n",
    "    valid_size = len(DS1[i]) - train_size\n",
    "\n",
    "    train_data, valid_data = torch.utils.data.random_split(DS1[i], [train_size, valid_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 128)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = 128)\n",
    "\n",
    "    for epoch in range(40):\n",
    "        print(\"epoch = \", epoch)\n",
    "        train(net, data_loader = train_loader,\n",
    "              data_size = train_size,\n",
    "              criterion = nn.CrossEntropyLoss(),\n",
    "              optimizer = optim.Adam(net.parameters(), lr = 2e-3))\n",
    "\n",
    "        validate(net, data_loader = valid_loader,\n",
    "                 data_size = valid_size,\n",
    "                 criterion = nn.CrossEntropyLoss(),\n",
    "                 model_name = str(i) + \"mainbody\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练（带翼）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Training model %d 0\n",
      "-----------------------------------------\n",
      "Training Avg. Loss: 0.020236, Accuracy: 0.703086\n",
      "Validation Avg. Loss: 0.027811, Accuracy: 0.614731\n",
      "Training Avg. Loss: 0.007777, Accuracy: 0.887280\n",
      "Validation Avg. Loss: 0.014672, Accuracy: 0.804533\n",
      "Training Avg. Loss: 0.005346, Accuracy: 0.904282\n",
      "Validation Avg. Loss: 0.012303, Accuracy: 0.818697\n",
      "Training Avg. Loss: 0.004064, Accuracy: 0.932935\n",
      "Validation Avg. Loss: 0.009874, Accuracy: 0.847025\n",
      "Training Avg. Loss: 0.003234, Accuracy: 0.947103\n",
      "Validation Avg. Loss: 0.010340, Accuracy: 0.821530\n",
      "Training Avg. Loss: 0.003344, Accuracy: 0.941436\n",
      "Validation Avg. Loss: 0.011472, Accuracy: 0.818697\n",
      "Training Avg. Loss: 0.002781, Accuracy: 0.948992\n",
      "Validation Avg. Loss: 0.009851, Accuracy: 0.841360\n",
      "Training Avg. Loss: 0.001970, Accuracy: 0.968829\n",
      "Validation Avg. Loss: 0.009216, Accuracy: 0.875354\n",
      "Training Avg. Loss: 0.002005, Accuracy: 0.967884\n",
      "Validation Avg. Loss: 0.008729, Accuracy: 0.858357\n",
      "Training Avg. Loss: 0.002045, Accuracy: 0.964736\n",
      "Validation Avg. Loss: 0.010106, Accuracy: 0.852691\n",
      "Training Avg. Loss: 0.001854, Accuracy: 0.964736\n",
      "Validation Avg. Loss: 0.010760, Accuracy: 0.835694\n",
      "Training Avg. Loss: 0.001444, Accuracy: 0.977015\n",
      "Validation Avg. Loss: 0.009369, Accuracy: 0.875354\n",
      "Training Avg. Loss: 0.001230, Accuracy: 0.980793\n",
      "Validation Avg. Loss: 0.009091, Accuracy: 0.864023\n",
      "Training Avg. Loss: 0.001569, Accuracy: 0.967569\n",
      "Validation Avg. Loss: 0.010934, Accuracy: 0.844193\n",
      "Training Avg. Loss: 0.001233, Accuracy: 0.979534\n",
      "Validation Avg. Loss: 0.011281, Accuracy: 0.835694\n",
      "Training Avg. Loss: 0.001241, Accuracy: 0.981423\n",
      "Validation Avg. Loss: 0.009997, Accuracy: 0.852691\n",
      "Training Avg. Loss: 0.001058, Accuracy: 0.981738\n",
      "Validation Avg. Loss: 0.011365, Accuracy: 0.855524\n",
      "Training Avg. Loss: 0.000884, Accuracy: 0.989295\n",
      "Validation Avg. Loss: 0.012452, Accuracy: 0.835694\n",
      "Training Avg. Loss: 0.000873, Accuracy: 0.986146\n",
      "Validation Avg. Loss: 0.012684, Accuracy: 0.852691\n",
      "Training Avg. Loss: 0.000759, Accuracy: 0.987091\n",
      "Validation Avg. Loss: 0.011327, Accuracy: 0.861190\n",
      "Training Avg. Loss: 0.000768, Accuracy: 0.989295\n",
      "Validation Avg. Loss: 0.010490, Accuracy: 0.861190\n",
      "Training Avg. Loss: 0.000678, Accuracy: 0.991184\n",
      "Validation Avg. Loss: 0.011460, Accuracy: 0.852691\n",
      "Training Avg. Loss: 0.000735, Accuracy: 0.987091\n",
      "Validation Avg. Loss: 0.009810, Accuracy: 0.855524\n",
      "Training Avg. Loss: 0.000715, Accuracy: 0.985831\n",
      "Validation Avg. Loss: 0.009780, Accuracy: 0.872521\n",
      "Training Avg. Loss: 0.000650, Accuracy: 0.986776\n",
      "Validation Avg. Loss: 0.010331, Accuracy: 0.858357\n",
      "Training Avg. Loss: 0.000714, Accuracy: 0.988350\n",
      "Validation Avg. Loss: 0.011983, Accuracy: 0.830028\n",
      "Training Avg. Loss: 0.000628, Accuracy: 0.988980\n",
      "Validation Avg. Loss: 0.012013, Accuracy: 0.844193\n",
      "Training Avg. Loss: 0.000734, Accuracy: 0.984572\n",
      "Validation Avg. Loss: 0.012079, Accuracy: 0.844193\n",
      "Training Avg. Loss: 0.000580, Accuracy: 0.991499\n",
      "Validation Avg. Loss: 0.011441, Accuracy: 0.855524\n",
      "Training Avg. Loss: 0.000620, Accuracy: 0.987720\n",
      "Validation Avg. Loss: 0.012399, Accuracy: 0.844193\n",
      "Training Avg. Loss: 0.000536, Accuracy: 0.990869\n",
      "Validation Avg. Loss: 0.013664, Accuracy: 0.838527\n",
      "Training Avg. Loss: 0.000417, Accuracy: 0.992758\n",
      "Validation Avg. Loss: 0.012349, Accuracy: 0.844193\n",
      "Training Avg. Loss: 0.000393, Accuracy: 0.993388\n",
      "Validation Avg. Loss: 0.012821, Accuracy: 0.858357\n",
      "Training Avg. Loss: 0.000540, Accuracy: 0.990239\n",
      "Validation Avg. Loss: 0.014493, Accuracy: 0.832861\n",
      "Training Avg. Loss: 0.000666, Accuracy: 0.984572\n",
      "Validation Avg. Loss: 0.014732, Accuracy: 0.847025\n",
      "Training Avg. Loss: 0.000496, Accuracy: 0.989610\n",
      "Validation Avg. Loss: 0.013903, Accuracy: 0.841360\n",
      "Training Avg. Loss: 0.000622, Accuracy: 0.986776\n",
      "Validation Avg. Loss: 0.014314, Accuracy: 0.838527\n",
      "Training Avg. Loss: 0.000607, Accuracy: 0.987406\n",
      "Validation Avg. Loss: 0.014279, Accuracy: 0.849858\n",
      "Training Avg. Loss: 0.000429, Accuracy: 0.991814\n",
      "Validation Avg. Loss: 0.013640, Accuracy: 0.852691\n",
      "Training Avg. Loss: 0.000356, Accuracy: 0.993073\n",
      "Validation Avg. Loss: 0.013559, Accuracy: 0.869688\n",
      "-----------------------------------------\n",
      "Training model %d 1\n",
      "-----------------------------------------\n",
      "Training Avg. Loss: 0.025523, Accuracy: 0.706950\n",
      "Validation Avg. Loss: 0.036497, Accuracy: 0.595349\n",
      "Training Avg. Loss: 0.017266, Accuracy: 0.753112\n",
      "Validation Avg. Loss: 0.026764, Accuracy: 0.655814\n",
      "Training Avg. Loss: 0.008823, Accuracy: 0.860477\n",
      "Validation Avg. Loss: 0.018564, Accuracy: 0.702326\n",
      "Training Avg. Loss: 0.006556, Accuracy: 0.897303\n",
      "Validation Avg. Loss: 0.017332, Accuracy: 0.711628\n",
      "Training Avg. Loss: 0.007094, Accuracy: 0.880187\n",
      "Validation Avg. Loss: 0.019830, Accuracy: 0.655814\n",
      "Training Avg. Loss: 0.005063, Accuracy: 0.917012\n",
      "Validation Avg. Loss: 0.018420, Accuracy: 0.697674\n",
      "Training Avg. Loss: 0.003851, Accuracy: 0.934647\n",
      "Validation Avg. Loss: 0.015920, Accuracy: 0.744186\n",
      "Training Avg. Loss: 0.003628, Accuracy: 0.940353\n",
      "Validation Avg. Loss: 0.017971, Accuracy: 0.716279\n",
      "Training Avg. Loss: 0.003382, Accuracy: 0.937759\n",
      "Validation Avg. Loss: 0.016919, Accuracy: 0.767442\n",
      "Training Avg. Loss: 0.003117, Accuracy: 0.943983\n",
      "Validation Avg. Loss: 0.015859, Accuracy: 0.758140\n",
      "Training Avg. Loss: 0.002758, Accuracy: 0.959025\n",
      "Validation Avg. Loss: 0.017224, Accuracy: 0.702326\n",
      "Training Avg. Loss: 0.002648, Accuracy: 0.961100\n",
      "Validation Avg. Loss: 0.017136, Accuracy: 0.739535\n",
      "Training Avg. Loss: 0.002276, Accuracy: 0.965768\n",
      "Validation Avg. Loss: 0.017464, Accuracy: 0.767442\n",
      "Training Avg. Loss: 0.001899, Accuracy: 0.967324\n",
      "Validation Avg. Loss: 0.018242, Accuracy: 0.748837\n",
      "Training Avg. Loss: 0.001980, Accuracy: 0.969398\n",
      "Validation Avg. Loss: 0.018407, Accuracy: 0.725581\n",
      "Training Avg. Loss: 0.001814, Accuracy: 0.976660\n",
      "Validation Avg. Loss: 0.018662, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.002004, Accuracy: 0.968880\n",
      "Validation Avg. Loss: 0.018449, Accuracy: 0.744186\n",
      "Training Avg. Loss: 0.001626, Accuracy: 0.978734\n",
      "Validation Avg. Loss: 0.019059, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.001580, Accuracy: 0.977697\n",
      "Validation Avg. Loss: 0.019083, Accuracy: 0.744186\n",
      "Training Avg. Loss: 0.001640, Accuracy: 0.974066\n",
      "Validation Avg. Loss: 0.019340, Accuracy: 0.706977\n",
      "Training Avg. Loss: 0.001307, Accuracy: 0.980290\n",
      "Validation Avg. Loss: 0.019285, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.001703, Accuracy: 0.984440\n",
      "Validation Avg. Loss: 0.019584, Accuracy: 0.753488\n",
      "Training Avg. Loss: 0.001835, Accuracy: 0.971992\n",
      "Validation Avg. Loss: 0.021198, Accuracy: 0.697674\n",
      "Training Avg. Loss: 0.001109, Accuracy: 0.983402\n",
      "Validation Avg. Loss: 0.020641, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.001243, Accuracy: 0.981846\n",
      "Validation Avg. Loss: 0.020678, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.001233, Accuracy: 0.981846\n",
      "Validation Avg. Loss: 0.020528, Accuracy: 0.706977\n",
      "Training Avg. Loss: 0.000999, Accuracy: 0.986515\n",
      "Validation Avg. Loss: 0.020111, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.001057, Accuracy: 0.981846\n",
      "Validation Avg. Loss: 0.020426, Accuracy: 0.706977\n",
      "Training Avg. Loss: 0.000941, Accuracy: 0.986515\n",
      "Validation Avg. Loss: 0.021463, Accuracy: 0.706977\n",
      "Training Avg. Loss: 0.000807, Accuracy: 0.988589\n",
      "Validation Avg. Loss: 0.018964, Accuracy: 0.739535\n",
      "Training Avg. Loss: 0.000876, Accuracy: 0.988071\n",
      "Validation Avg. Loss: 0.022175, Accuracy: 0.720930\n",
      "Training Avg. Loss: 0.000857, Accuracy: 0.988071\n",
      "Validation Avg. Loss: 0.021729, Accuracy: 0.725581\n",
      "Training Avg. Loss: 0.000876, Accuracy: 0.990145\n",
      "Validation Avg. Loss: 0.021644, Accuracy: 0.744186\n",
      "Training Avg. Loss: 0.000853, Accuracy: 0.989108\n",
      "Validation Avg. Loss: 0.022457, Accuracy: 0.711628\n",
      "Training Avg. Loss: 0.000777, Accuracy: 0.989627\n",
      "Validation Avg. Loss: 0.021821, Accuracy: 0.702326\n",
      "Training Avg. Loss: 0.000673, Accuracy: 0.993257\n",
      "Validation Avg. Loss: 0.023838, Accuracy: 0.706977\n",
      "Training Avg. Loss: 0.000690, Accuracy: 0.990145\n",
      "Validation Avg. Loss: 0.021005, Accuracy: 0.711628\n",
      "Training Avg. Loss: 0.000692, Accuracy: 0.988589\n",
      "Validation Avg. Loss: 0.021609, Accuracy: 0.716279\n",
      "Training Avg. Loss: 0.000607, Accuracy: 0.993776\n",
      "Validation Avg. Loss: 0.024481, Accuracy: 0.702326\n",
      "Training Avg. Loss: 0.000951, Accuracy: 0.990145\n",
      "Validation Avg. Loss: 0.023415, Accuracy: 0.693023\n",
      "-----------------------------------------\n",
      "Training model %d 2\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Avg. Loss: 0.021504, Accuracy: 0.707235\n",
      "Validation Avg. Loss: 0.029234, Accuracy: 0.592965\n",
      "Training Avg. Loss: 0.009758, Accuracy: 0.864274\n",
      "Validation Avg. Loss: 0.017874, Accuracy: 0.778894\n",
      "Training Avg. Loss: 0.006933, Accuracy: 0.905216\n",
      "Validation Avg. Loss: 0.014701, Accuracy: 0.809045\n",
      "Training Avg. Loss: 0.005343, Accuracy: 0.910824\n",
      "Validation Avg. Loss: 0.012797, Accuracy: 0.778894\n",
      "Training Avg. Loss: 0.004479, Accuracy: 0.930454\n",
      "Validation Avg. Loss: 0.012245, Accuracy: 0.814070\n",
      "Training Avg. Loss: 0.004500, Accuracy: 0.927089\n",
      "Validation Avg. Loss: 0.011974, Accuracy: 0.829146\n",
      "Training Avg. Loss: 0.003653, Accuracy: 0.943915\n",
      "Validation Avg. Loss: 0.009680, Accuracy: 0.844221\n",
      "Training Avg. Loss: 0.003154, Accuracy: 0.948962\n",
      "Validation Avg. Loss: 0.011024, Accuracy: 0.824121\n",
      "Training Avg. Loss: 0.002701, Accuracy: 0.960179\n",
      "Validation Avg. Loss: 0.010312, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.002591, Accuracy: 0.956254\n",
      "Validation Avg. Loss: 0.010795, Accuracy: 0.824121\n",
      "Training Avg. Loss: 0.002850, Accuracy: 0.952888\n",
      "Validation Avg. Loss: 0.014803, Accuracy: 0.814070\n",
      "Training Avg. Loss: 0.002224, Accuracy: 0.963545\n",
      "Validation Avg. Loss: 0.011900, Accuracy: 0.859296\n",
      "Training Avg. Loss: 0.001911, Accuracy: 0.965788\n",
      "Validation Avg. Loss: 0.012051, Accuracy: 0.844221\n",
      "Training Avg. Loss: 0.001866, Accuracy: 0.971397\n",
      "Validation Avg. Loss: 0.012120, Accuracy: 0.798995\n",
      "Training Avg. Loss: 0.001549, Accuracy: 0.975883\n",
      "Validation Avg. Loss: 0.011439, Accuracy: 0.849246\n",
      "Training Avg. Loss: 0.001547, Accuracy: 0.977005\n",
      "Validation Avg. Loss: 0.013656, Accuracy: 0.819095\n",
      "Training Avg. Loss: 0.001154, Accuracy: 0.983174\n",
      "Validation Avg. Loss: 0.014430, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.001224, Accuracy: 0.983174\n",
      "Validation Avg. Loss: 0.012966, Accuracy: 0.849246\n",
      "Training Avg. Loss: 0.001143, Accuracy: 0.980931\n",
      "Validation Avg. Loss: 0.013012, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.001180, Accuracy: 0.978688\n",
      "Validation Avg. Loss: 0.014479, Accuracy: 0.819095\n",
      "Training Avg. Loss: 0.001360, Accuracy: 0.976444\n",
      "Validation Avg. Loss: 0.011984, Accuracy: 0.839196\n",
      "Training Avg. Loss: 0.000910, Accuracy: 0.987100\n",
      "Validation Avg. Loss: 0.012483, Accuracy: 0.829146\n",
      "Training Avg. Loss: 0.000813, Accuracy: 0.985418\n",
      "Validation Avg. Loss: 0.012239, Accuracy: 0.819095\n",
      "Training Avg. Loss: 0.001141, Accuracy: 0.980370\n",
      "Validation Avg. Loss: 0.012857, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.000678, Accuracy: 0.988783\n",
      "Validation Avg. Loss: 0.012827, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.000774, Accuracy: 0.989344\n",
      "Validation Avg. Loss: 0.012397, Accuracy: 0.854271\n",
      "Training Avg. Loss: 0.000903, Accuracy: 0.984857\n",
      "Validation Avg. Loss: 0.014940, Accuracy: 0.839196\n",
      "Training Avg. Loss: 0.000708, Accuracy: 0.989905\n",
      "Validation Avg. Loss: 0.014036, Accuracy: 0.819095\n",
      "Training Avg. Loss: 0.000726, Accuracy: 0.989344\n",
      "Validation Avg. Loss: 0.014238, Accuracy: 0.849246\n",
      "Training Avg. Loss: 0.000865, Accuracy: 0.984296\n",
      "Validation Avg. Loss: 0.015278, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.000596, Accuracy: 0.993270\n",
      "Validation Avg. Loss: 0.015748, Accuracy: 0.809045\n",
      "Training Avg. Loss: 0.000515, Accuracy: 0.992709\n",
      "Validation Avg. Loss: 0.015156, Accuracy: 0.844221\n",
      "Training Avg. Loss: 0.000658, Accuracy: 0.988783\n",
      "Validation Avg. Loss: 0.018700, Accuracy: 0.814070\n",
      "Training Avg. Loss: 0.000427, Accuracy: 0.993270\n",
      "Validation Avg. Loss: 0.014899, Accuracy: 0.814070\n",
      "Training Avg. Loss: 0.000487, Accuracy: 0.993831\n",
      "Validation Avg. Loss: 0.017622, Accuracy: 0.829146\n",
      "Training Avg. Loss: 0.000323, Accuracy: 0.998317\n",
      "Validation Avg. Loss: 0.017514, Accuracy: 0.819095\n",
      "Training Avg. Loss: 0.000677, Accuracy: 0.987661\n",
      "Validation Avg. Loss: 0.016915, Accuracy: 0.829146\n",
      "Training Avg. Loss: 0.000388, Accuracy: 0.994391\n",
      "Validation Avg. Loss: 0.015069, Accuracy: 0.834171\n",
      "Training Avg. Loss: 0.000395, Accuracy: 0.996635\n",
      "Validation Avg. Loss: 0.014998, Accuracy: 0.849246\n",
      "Training Avg. Loss: 0.000358, Accuracy: 0.993831\n",
      "Validation Avg. Loss: 0.015361, Accuracy: 0.834171\n"
     ]
    }
   ],
   "source": [
    "net = MyModule(_input_size, 28)\n",
    "best_acc = 0\n",
    "\n",
    "train_size = int(0.9 * len(DS2))\n",
    "valid_size = len(DS2) - train_size\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(DS2, [train_size, valid_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 64)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = 64)\n",
    "\n",
    "for epoch in range(40):\n",
    "\n",
    "    train(net, data_loader = train_loader,\n",
    "           data_size = train_size,\n",
    "           criterion = nn.CrossEntropyLoss(),\n",
    "           optimizer = optim.Adam(net.parameters(), lr = 2e-3))\n",
    "\n",
    "    validate(net, data_loader = valid_loader,\n",
    "              data_size = valid_size,\n",
    "              criterion = nn.CrossEntropyLoss(),\n",
    "              model_name = str(i) + \"bywings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"requests\":[ {\"bid\":[0, 0],\"own\":[8, \t\t\t\t\t\t30, \t\t\t\t\t\t1, \t\t\t\t\t\t32, \t\t\t\t\t\t22, \t\t\t\t\t\t28, \t\t\t\t\t\t33, \t\t\t\t\t\t24, \t\t\t\t\t\t31, \t\t\t\t\t\t41, \t\t\t\t\t\t42, \t\t\t\t\t\t25, \t\t\t\t\t\t51, \t\t\t\t\t\t19, \t\t\t\t\t\t46, \t\t\t\t\t\t5, \t\t\t\t\t\t26]}, { \"history\": [ \t\t\t\t\t\t[ \t\t\t\t\t\t\t0, \t\t\t\t\t\t\t9, \t\t\t\t\t\t\t10, \t\t\t\t\t\t\t11 \t\t\t\t\t\t], \t\t\t\t\t\t[] \t\t\t\t\t], \t\t\t\t\t\"own\": [ \t\t\t\t\t\t8, \t\t\t\t\t\t30, \t\t\t\t\t\t1, \t\t\t\t\t\t32, \t\t\t\t\t\t22, \t\t\t\t\t\t28, \t\t\t\t\t\t33, \t\t\t\t\t\t24, \t\t\t\t\t\t31, \t\t\t\t\t\t41, \t\t\t\t\t\t42, \t\t\t\t\t\t25, \t\t\t\t\t\t51, \t\t\t\t\t\t19, \t\t\t\t\t\t46, \t\t\t\t\t\t5, \t\t\t\t\t\t26 \t\t\t\t\t], \t\t\t\t\t\"publiccard\": [ \t\t\t\t\t\t21, \t\t\t\t\t\t38, \t\t\t\t\t\t9 \t\t\t\t\t], \t\t\t\t\t\"landlord\": 0, \t\t\t\t\t\"pos\": 2, \t\t\t\t\t\"finalbid\": 1 \t\t\t\t\t} ],\"responses\":[1]}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-6d6c732ceda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mBIDDING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mPLAYING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-6d6c732ceda0>\u001b[0m in \u001b[0;36mPLAYING\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcombo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         combo_id = model(torch.from_numpy(g.getInput(my_pos)).unsqueeze(0),\n\u001b[0m\u001b[1;32m     36\u001b[0m                          torch.from_numpy(mask)).unsqueeze(0).detach().numpy().argmax()\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-93-1e7829909f88>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, m)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2052\u001b[0m                 bias=bias, training=training, momentum=momentum, eps=eps)\n\u001b[1;32m   2053\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])"
     ]
    }
   ],
   "source": [
    "my_hand = []\n",
    "g = Game([[], [], []])\n",
    "my_pos = -1\n",
    "others = []\n",
    "las_combo = (0, 0, 0, 0)\n",
    "\n",
    "def BIDDING():\n",
    "    bid_val = 0\n",
    "    print(json.dumps({\n",
    "        \"response\": bid_val\n",
    "    }))\n",
    "    assert(0)\n",
    "    exit()\n",
    "\n",
    "def PLAYING():\n",
    "    def getFromHand(idx):\n",
    "        global my_hand\n",
    "        for c in my_hand:\n",
    "            if getCardId(c) == idx:\n",
    "                my_hand.remove(c)\n",
    "                return c\n",
    "    \n",
    "    to_play = []\n",
    "    \n",
    "    model_path = \"./model/\"\n",
    "    model_name = \"best_model_for_\" + str(my_pos) + \"mainbody.pt\"\n",
    "    model = MyModule(_input_size, combo_cnt)\n",
    "    model.load_state_dict(torch.load(model_path + model_name))\n",
    "    \n",
    "    mask = g.getMask1(my_pos, las_combo)\n",
    "    combo_id = -1\n",
    "    if np.sum(mask) == 1:\n",
    "        combo_id = np.argmax(mask)\n",
    "    else:\n",
    "        combo_id = model(torch.from_numpy(g.getInput(my_pos)).unsqueeze(0),\n",
    "                         torch.from_numpy(mask)).unsqueeze(0).detach().numpy().argmax()\n",
    "    \n",
    "    combo = combo_list[combo_id]\n",
    "    for i in range(combo[1], combo[2] + 1):\n",
    "        for j in range(combo[0]):\n",
    "            to_play.append(getFromHand(i))\n",
    "    g.play(my_pos, to_play)\n",
    "    \n",
    "    if combo[3] != 0:\n",
    "        model_name = \"best_model_for_\" + str(my_pos) + \"bywings.pt\"\n",
    "        model = MyModule(_input_size, 28)\n",
    "        model.load_state_dict(torch.load(model_path + model_name))\n",
    "\n",
    "        cnt = (combo[2] - combo[1] + 1) * (1 if combo[0] == 3 else 2)\n",
    "        already_played = []\n",
    "        for i in range(cnt):\n",
    "            wing_id = model(torch.from_numpy(g.getInput(my_pos)),\n",
    "                            torch.from_numpy(g.getMask2(my_pos, combo, already_played))).detach().numpy().argmax()\n",
    "            tmp = []\n",
    "            if wing_id < 15:\n",
    "                tmp = [getFromHand(wing_id)]\n",
    "            else:\n",
    "                wing_id -= 15\n",
    "                tmp = [getFromHand(wing_id), getFromHand(wing_id)]\n",
    "            g.play(my_pos, tmp)\n",
    "            to_play.extend(tmp)\n",
    "            already_played.append(wing_id)\n",
    "    \n",
    "    print(json.dumps({\n",
    "        \"response\": to_play\n",
    "    }))\n",
    "    assert 0\n",
    "    exit()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    initCombo()\n",
    "    data = json.loads(input())\n",
    "    my_hand, others_hand = data[\"requests\"][0][\"own\"], []\n",
    "    for i in range(54):\n",
    "        if i not in my_hand:\n",
    "            others_hand.append(i)\n",
    "\n",
    "    TODO = \"bidding\"\n",
    "    if \"bid\" in data[\"requests\"][0]:\n",
    "        bid_list = data[\"requests\"][0][\"bid\"]\n",
    "    \n",
    "    for i in range(len(data[\"requests\"])):\n",
    "        request = data[\"requests\"][i]\n",
    "        if \"publiccard\" in request:\n",
    "            bot_pos = request[\"pos\"]\n",
    "            lord_pos = request[\"landlord\"]\n",
    "            my_pos = (bot_pos - lord_pos + 3) % 3\n",
    "            others = [(my_pos + 1) % 3, (my_pos + 2) % 3]\n",
    "            tmp = [[], [], []]\n",
    "            if my_pos == 0:\n",
    "                my_hand.extend(request[\"publiccard\"])\n",
    "                tmp[0] = my_hand\n",
    "                tmp[1], tmp[2] = others_hand[:17], others_hand[17:] # 随便分\n",
    "            else:\n",
    "                tmp[my_pos] = my_hand\n",
    "                tmp[0] = others_hand[:20]\n",
    "                tmp[2 if my_pos == 1 else 1] = others_hand[20:]\n",
    "            g = Game(tmp)\n",
    "        if \"history\" in request:\n",
    "            history = request[\"history\"]\n",
    "            TODO = \"playing\"\n",
    "            for j in range(2):\n",
    "                p = others[j]\n",
    "                cards = history[j]\n",
    "                g.play(p, cards)\n",
    "                cur_combo = getCombo(cards)\n",
    "                if cur_combo != (0, 0, 0, 0):\n",
    "                    las_combo = cur_combo\n",
    "\n",
    "            if i < len(data[\"requests\"]) - 1:\n",
    "                cards = data[\"responses\"][i]\n",
    "                g.play(my_pos, cards)\n",
    "    \n",
    "    if TODO == \"bidding\":\n",
    "        BIDDING()\n",
    "    else:\n",
    "        PLAYING()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
